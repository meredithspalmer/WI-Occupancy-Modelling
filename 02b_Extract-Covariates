#################################################################################
### Extract static and dynamic covariates #######################################
#################################################################################

# This file contains code to create a preannotated version of the covariates for 
# the occupancy models. The types of covariates are: 

# * site-level covariates (static). Format: cells x 1 column per each covariate;
# * primary period-level covariates (dynamic). Format: cells x periods per each covariate. 
#       Some of these covariates (e.g. year) will have the repeated values in more than 
#       one column

# Run ONCE but note: this extracts values for cell_IDs present in the WI dataset;
# if you add sites to the dataset, you will need to re-extract the covariates 

# set workspace -----------------------------------------------------------------
setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/10x10 km spatial layers")
rm(list=ls()); gc()

library(terra)
library(stringr)
library(raster)
library(dplyr)
library(tidyr)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(arrow)
library(purrr)
library(parallel)
library(glmnet)
library(mgcv)


# Set up reference raster -----------------------------------------------------

# Load reference
reference <- rast("raster_100km2_with_cellID.tif")

## If only want covs for study sites -- 

# Limit to cell_IDs present in dataset 
site_cells <- read.csv("WI_loc_matching_cell_ID.csv") 

# Mask reference raster 
reference_sub <- mask(reference, reference %in% site_cells$cell_ID, maskvalues=F) 

## If want all terrestrial areas --

# Get land polygons
land <- ne_countries(scale = "medium", returnclass = "sf")
land_terra <- vect(land)

# Reproject if needed
if (crs(reference) != crs(land_terra)) {
  land_terra <- project(land_terra, crs(reference))
}

# Mask to land
reference_land <- mask(reference, land_terra)

## Static layers --------------------------------------------------------------

# Read TIF files for static layers 
static_layers <- list(
  road_dist = rast("roads_100km2.tif"),
  elevation = rast("ele_100km2.tif"),
  tri       = rast("tri_100km2.tif"),
  river_dist= rast("riv_100km2.tif"),
  coeff_var = rast("cv_100km2.tif"),
  cities_lg = rast("humacc_large_100km2.tif"),
  cities_md = rast("humacc_medium_100km2.tif"),
  cities_sm = rast("humacc_small_100km2.tif")
)
r_c <- rast(static_layers)

# Extract cell_IDs
#extracted <- terra::zonal(r_c, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
extracted <- terra::zonal(r_c, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
coords <- as.data.frame(reference, xy=T)
extracted <- merge(extracted, coords, all.x=T) %>% distinct()

# Extrapolate missing values (using linear models; fills in mean when unable to model)
extracted[] <- lapply(extracted, function(z) { 
  if (is.numeric(z)) { z[is.nan(z)] <- NA_real_ }
  z
})

covariate_cols <- setdiff(names(extracted),  c("cell_ID", "x", "y"))
covariate_cols <- covariate_cols[sapply(extracted[covariate_cols], is.numeric)]

for (cov in covariate_cols) {
  miss <- which(is.na(extracted[[cov]]))
  if (!length(miss)) next  # nothing to fill for this covariate
  
  # training rows (response present and coords present)
  train_rows <- which(!is.na(extracted[[cov]]) & 
                        !is.na(extracted$x) & !is.na(extracted$y))
  if (!length(train_rows)) next  # can't train anything; skip
  
  # candidate numeric predictors (besides the target)
  preds_all <- setdiff(covariate_cols, cov)
  
  # keep predictors that have at least some non-NA and non-zero variance on training data
  good_preds <- preds_all[sapply(preds_all, function(p) {
    v <- extracted[[p]][train_rows]
    any(!is.na(v)) && (is.numeric(v)) && (var(v, na.rm = TRUE) > 0)
  })]
  
  # Full model: cov ~ x + y + good_preds 
  full_predictors <- c("x", "y", good_preds)
  fit_dat_full <- extracted[train_rows, c(cov, full_predictors)]
  fit_dat_full <- fit_dat_full[complete.cases(fit_dat_full), ]
  
  if (nrow(fit_dat_full) >= 5) {
    fit_full <- lm(reformulate(full_predictors, response = cov), data = fit_dat_full)
    
    # predict where all required predictors are present
    can_pred_full <- miss[complete.cases(extracted[miss, full_predictors])]
    if (length(can_pred_full)) {
      extracted[can_pred_full, cov] <- predict(fit_full, newdata = extracted[can_pred_full, ])
      miss <- setdiff(miss, can_pred_full)
    }
  }
  
  # Fallback: cov ~ x + y 
  if (length(miss)) {
    fit_dat_xy <- extracted[train_rows, c(cov, "x", "y")]
    fit_dat_xy <- fit_dat_xy[complete.cases(fit_dat_xy), ]
    if (nrow(fit_dat_xy) >= 3) {
      fit_xy <- lm(as.formula(paste(cov, "~ x + y")), data = fit_dat_xy)
      can_pred_xy <- miss[complete.cases(extracted[miss, c("x","y")])]
      if (length(can_pred_xy)) {
        extracted[can_pred_xy, cov] <- predict(fit_xy, newdata = extracted[can_pred_xy, ])
        miss <- setdiff(miss, can_pred_xy)
      }
    }
  }
  
  # Last resort: fill with column mean  
  if (length(miss)) {
    mu <- mean(extracted[[cov]], na.rm = TRUE)
    extracted[miss, cov] <- mu
  }
}

# Save 
#write.csv(extracted, "../Covariates for modelling/site_level_covariates.csv", row.names = FALSE)
write.csv(extracted, "../Covariates for modelling/site_level_covariates_full.csv", row.names = FALSE)


## Dynamic layers -------------------------------------------------------------

# Create period template ------------------------------------------------------
min_year <- 2000  
max_year <- 2024 
range_year <- c(min_year, max_year)
min_date <- as.Date(paste(range_year[1] - 1, "-12-01", sep = ""))
max_date <- as.Date(paste(range_year[2] + 1, "-03-01", sep = "")) 
start_period <-  seq.Date(min_date, max_date, by =  "91 day") #"3 month"
end_period <-  c(start_period[-1] - 1, NA)

periods <- data.frame(period = paste("Period", seq(1, length(start_period), by = 1), sep = "_"),
                      start_period = start_period, 
                      end_period = end_period) 
periods <- periods[-nrow(periods),]
periods$season <- rep(c("Winter", "Spring", "Summer", "Fall"), length.out = nrow(periods))
periods$year <- year(periods$start_period)
periods$period_counter <- 1:nrow(periods)
head(periods)

## Annual dynamic layers ------------------------------------------------------

## Read TIF files for ANNUAL PRECIP ---    
r_list <- list(
  precip_1999 = rast("annprec_2010_100km2.tif"),
  precip_2011 = rast("annprec_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
#extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
extracted <- terra::zonal(r_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Reshape and interpolate for 2000–2024
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>% #WHY IS THIS NEGATIVE? HERE AND THROUGHOUT 
  mutate(year = as.numeric(str_remove(year, "precip_"))) %>%
  group_by(cell_ID) %>%
  summarise(
    start_year = min(year, na.rm = TRUE),
    end_year   = max(year, na.rm = TRUE),
    start_cov  = cov[year == min(year, na.rm = TRUE)],
    end_cov    = cov[year == max(year, na.rm = TRUE)],
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(preds = list({
    if (is.na(start_cov) || is.na(end_cov)) {
      tibble(year = periods$year, cov = NA_real_)
    } else {
      tibble(
        year = periods$year,
        cov  = approx(
          x = c(start_year, end_year),
          y = c(start_cov, end_cov),
          xout = periods$year,
          rule = 2
        )$y
      )
    }
  })) %>%
  unnest(preds) %>%
  ungroup() %>% 
  distinct()

# Expand to seasons (4 rows per year) 
cov_df <- cov_df %>%
  left_join(periods %>% dplyr::select(year, period_counter), by = "year", relationship = "many-to-many") %>%
  dplyr::select(cell_ID, period_counter, cov)

# Pivot to final matrix 
cov_df <- cov_df %>%
  pivot_wider(
    id_cols = cell_ID,
    names_from = period_counter,
    values_from = cov,
    values_fill = NA
  ) %>%
  arrange(cell_ID) %>%
  as.matrix()

# Save 
#write.csv(cov_df, ../Covariates for modelling/"primary_occ_covariates_annprec_sites.csv", row.names = F)
write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_annprec_full.csv", row.names = F)


## Read TIF files for ANNUAL TEMP ---    
r_list <- list(
  temp_1999 = rast("anntemp_2010_100km2.tif"),
  temp_2011 = rast("anntemp_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
#extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
extracted <- terra::zonal(r_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Reshape and interpolate for 2000–2024
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>%
  mutate(year = as.numeric(str_remove(year, "temp_"))) %>% 
  group_by(cell_ID) %>%
  summarise(
    start_year = min(year, na.rm = TRUE),
    end_year   = max(year, na.rm = TRUE),
    start_cov  = cov[year == min(year, na.rm = TRUE)],
    end_cov    = cov[year == max(year, na.rm = TRUE)],
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(preds = list({
    if (is.na(start_cov) || is.na(end_cov)) {
      tibble(year = periods$year, cov = NA_real_)
    } else {
      tibble(
        year = periods$year,
        cov  = approx(
          x = c(start_year, end_year),
          y = c(start_cov, end_cov),
          xout = periods$year,
          rule = 2
        )$y
      )
    }
  })) %>%
  unnest(preds) %>%
  ungroup() %>% 
  distinct()

# Expand to seasons (4 rows per year) 
cov_df <- cov_df %>%
  left_join(periods %>% dplyr::select(year, period_counter), by = "year", relationship = "many-to-many") %>%
  dplyr::select(cell_ID, period_counter, cov)

# Pivot to final matrix 
cov_df <- cov_df %>%
  pivot_wider(
    id_cols = cell_ID,
    names_from = period_counter,
    values_from = cov,
    values_fill = NA
  ) %>%
  arrange(cell_ID) %>%
  as.matrix()

# Save 
#write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_temp_sites.csv", row.names = F)
write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_temp_full.csv", row.names = F)


## Read TIF files for SEASONAL PRECIP ---    
r_list <- list(
  precseas_1999 = rast("precseas_2010_100km2.tif"),
  precseas_2011 = rast("precseas_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
#extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
extracted <- terra::zonal(r_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Reshape and interpolate for 2000–2024
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>%
  mutate(year = as.numeric(str_remove(year, "precseas_"))) %>%
  group_by(cell_ID) %>%
  summarise(
    start_year = min(year, na.rm = TRUE),
    end_year   = max(year, na.rm = TRUE),
    start_cov  = cov[year == min(year, na.rm = TRUE)],
    end_cov    = cov[year == max(year, na.rm = TRUE)],
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(preds = list({
    if (is.na(start_cov) || is.na(end_cov)) {
      tibble(year = periods$year, cov = NA_real_)
    } else {
      tibble(
        year = periods$year,
        cov  = approx(
          x = c(start_year, end_year),
          y = c(start_cov, end_cov),
          xout = periods$year,
          rule = 2
        )$y
      )
    }
  })) %>%
  unnest(preds) %>%
  ungroup() %>% 
  distinct()

# Expand to seasons (4 rows per year) ---
cov_df <- cov_df %>%
  left_join(periods %>% dplyr::select(year, period_counter), by = "year", relationship = "many-to-many") %>%
  dplyr::select(cell_ID, period_counter, cov)

# Pivot to final matrix ---
cov_df <- cov_df %>%
  pivot_wider(
    id_cols = cell_ID,
    names_from = period_counter,
    values_from = cov,
    values_fill = NA
  ) %>%
  arrange(cell_ID) %>%
  as.matrix()

# Save 
#write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_precseas_sites.csv", row.names = F)
write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_precseas_full.csv", row.names = F)


# Read TIF files for WARMEST SEASON PRECIP ---    
r_list <- list(
  warmseas_1999 = rast("precwarm_2010_100km2.tif"),
  warmseas_2011 = rast("precwarm_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
#extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
extracted <- terra::zonal(r_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Reshape and interpolate for 2000–2024
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>%
  mutate(year = as.numeric(str_remove(year, "warmseas_"))) %>% 
  group_by(cell_ID) %>%
  summarise(
    start_year = min(year, na.rm = TRUE),
    end_year   = max(year, na.rm = TRUE),
    start_cov  = cov[year == min(year, na.rm = TRUE)],
    end_cov    = cov[year == max(year, na.rm = TRUE)],
    .groups = "drop"
  ) %>%
  rowwise() %>%
  mutate(preds = list({
    if (is.na(start_cov) || is.na(end_cov)) {
      tibble(year = periods$year, cov = NA_real_)
    } else {
      tibble(
        year = periods$year,
        cov  = approx(
          x = c(start_year, end_year),
          y = c(start_cov, end_cov),
          xout = periods$year,
          rule = 2
        )$y
      )
    }
  })) %>%
  unnest(preds) %>%
  ungroup() %>% 
  distinct()

# Expand to seasons (4 rows per year) 
cov_df <- cov_df %>%
  left_join(periods %>% dplyr::select(year, period_counter), by = "year", relationship = "many-to-many") %>%
  dplyr::select(cell_ID, period_counter, cov)

# Pivot to final matrix 
cov_df <- cov_df %>%
  pivot_wider(
    id_cols = cell_ID,
    names_from = period_counter,
    values_from = cov,
    values_fill = NA
  ) %>%
  arrange(cell_ID) %>%
  as.matrix()

# Save 
#write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_warmseas_sites.csv", row.names = F)
write.csv(cov_df, "../Covariates for modelling/primary_occ_covariates_warmseas_full.csv", row.names = F)


## Read TIF files for GPW --- 

# Load files 
gwp_stack <- rast(list.files("GWP", full.names = TRUE))

# extract mean values for each cell_ID across all rasters in the stack
extracted <- terra::zonal(gwp_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
#extracted <- terra::zonal(gwp_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE)
head(extracted)

# to predict GPW for years between those with values (2000-2005-2010-2020-2024) with 95% CI 
custom_predict_lm <- function(fit, years) {
  pred <- predict(fit, newdata = data.frame(year = years))
  tibble(year = years, mean_GPW = pred)
}

future_years <- 2000:2024   

GPW_matrix <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>%
  mutate(year = as.numeric(str_remove(year, "GPW_"))) %>%
  group_by(cell_ID) %>%
  group_modify(~{
    df <- filter(.x, !is.na(cov))
    if (nrow(df) >= 2) {
      fit <- lm(cov ~ year, data = df)
      custom_predict_lm(fit, future_years)
    } else if (nrow(df) == 1) {
      # Not enough data for regression, return constant value
      tibble(year = future_years, mean_GPW = rep(df$cov[1], length(future_years)))
    } else {
      # No data at all
      tibble(year = future_years, mean_GPW = NA)
    }
  }) %>%
  ungroup() %>%
  dplyr::select(cell_ID, year, cov = mean_GPW) %>%
  pivot_wider(id_cols = cell_ID, names_from = year, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>%
  as.matrix()

# Save 
write.csv(GPW_matrix, "../Covariates for modelling/primary_occ_covariates_GPW_sites.csv", row.names = F)
#write.csv(GPW_matrix, "../Covariates for modelling/primary_occ_covariates_GPW_full.csv", row.names = F)


# Read TIF files for EVI ---
evi_files <- list.files("EVI", full.names = TRUE)
evi_list_raster <- lapply(evi_files, rast)
evi_stack <- rast(evi_list_raster)

# Name layers based on files (remove last 11 characters if needed)
names(evi_stack) <- gsub(".{11}$", "", basename(evi_files))

# Extract mean values for each cell_ID across all rasters in the stack
#extracted <- terra::zonal(evi_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
extracted <- terra::zonal(evi_stack, reference_land, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

df_long <- extracted %>%
  pivot_longer(
    cols = starts_with("evi_"),
    names_to = "date",
    values_to = "evi"
  ) %>%
  mutate(
    year = as.integer(str_extract(date, "(?<=evi_)\\d{4}")),
    doy  = as.integer(str_extract(date, "(?<=evi_\\d{4}_)\\d{3}")),
    evi  = ifelse(is.nan(evi), NA, evi)
  )

# -> for sites 
# Predict missing values 
impute_evi_ridge <- function(df_long) {
  
  X <- model.matrix(~ year + doy, df_long)[, -1]  # drop intercept (glmnet adds one)
  y <- df_long$evi
  
  # Fit ridge regression on non-missing data
  fit <- cv.glmnet(
    X[!is.na(y), ], 
    y[!is.na(y)], 
    alpha = 0,            # ridge regression
    nfolds = 5,
    standardize = TRUE
  )
  
  # Predict for ALL cells (including NAs)
  df_long$evi_filled <- as.numeric(predict(fit, newx = X, s = "lambda.min"))
  
  # Replace original values where missing 
  df_long <- df_long %>%
    mutate(evi_final = ifelse(is.na(evi), evi_filled, evi))
  
  df_long
}

result <- impute_evi_ridge(df_long) 

EVI_long <- result %>% 
  filter(year %in% periods$year) %>%
  mutate(year_str = str_extract(date, "(?<=evi_)\\d{4}"),
         doy_str  = str_extract(date, "(?<=evi_\\d{4}_)\\d{3}"),
         obs_date = as.Date(as.numeric(doy_str) - 1, 
                            origin = paste0(year_str, "-01-01"))) %>%
  dplyr::select(-year_str, -doy_str) %>% 
  dplyr::select(c(cell_ID, evi_final, obs_date)) %>% 
  rename(cov_value = evi_final, 
         date = obs_date)

EVI_joined <- EVI_long %>%
  left_join(periods %>% mutate(dummy = 1), by = character()) %>% 
  filter(date >= start_period & date <= end_period) %>% 
  group_by(cell_ID, period_counter) %>% #for when multiple values per cell per period 
  summarise(
    cov_value = mean(cov_value, na.rm = TRUE),
    .groups = "drop"
  )

EVI_mat <- EVI_joined %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(EVI_mat, "../Covariates for modelling/primary_occ_covariates_EVI_sites.csv", row.names = F)

# -> for global (use this raster in all modelling and predicting)

impute_evi_ridge_all_years <- function(df_long) {
  
  df_filled <- df_long %>%
    group_split(year) %>%
    map_dfr(function(chunk) {
      
      # Build model matrix and response
      X <- model.matrix(~ year + doy, chunk)[, -1]
      y <- chunk$evi
      
      # Fit ridge regression only if enough variation
      if(sum(!is.na(y)) >= 3 && length(unique(y[!is.na(y)])) > 1) {
        fit <- cv.glmnet(
          X[!is.na(y), ],
          y[!is.na(y)],
          alpha = 0,
          nfolds = min(5, sum(!is.na(y))),
          standardize = TRUE
        )
        chunk$evi_filled <- as.numeric(predict(fit, newx = X, s = "lambda.min"))
      } else {
        # Not enough data or no variation — leave as-is
        chunk$evi_filled <- chunk$evi
      }
      
      chunk %>%
        mutate(evi_final = ifelse(is.na(evi), evi_filled, evi))
    })
  
  return(df_filled)
}

result_long <- impute_evi_ridge_all_years(df_long)
head(result_long)
write.csv(result_long, "evi_save.csv", row.names=F)

EVI_long <- result_long %>% 
  filter(year %in% periods$year) %>%
  mutate(year_str = str_extract(date, "(?<=evi_)\\d{4}"),
         doy_str  = str_extract(date, "(?<=evi_\\d{4}_)\\d{3}"),
         obs_date = as.Date(as.numeric(doy_str) - 1, 
                            origin = paste0(year_str, "-01-01"))) %>%
  dplyr::select(-year_str, -doy_str) %>% 
  dplyr::select(c(cell_ID, evi_final, obs_date)) %>% 
  rename(cov_value = evi_final, 
         date = obs_date)

EVI_joined <- EVI_long %>%
  left_join(periods %>% mutate(dummy = 1), by = character()) %>% 
  filter(date >= start_period & date <= end_period) %>% 
  group_by(cell_ID, period_counter) %>% #for when multiple values per cell per period 
  summarise(
    cov_value = mean(cov_value, na.rm = TRUE),
    .groups = "drop"
  )
write.csv(EVI_joined, "evi_save_2.csv", row.names=F)

EVI_mat <- EVI_joined %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(EVI_mat, "../Covariates for modelling/primary_occ_covariates_EVI_full.csv", row.names = F)



# Read TIF files for GFC -- DO NOT DO YET! 

# GFC - 2001:2021 
gfc_list_raster <- NULL 
gfc <- list.files("../Raw spatial layers/GFC")
for(i in 1:length(gfc)){
  file.to.load <- paste0("../Raw spatial layers/GFC/",gfc[i])
  r <- rast(file.to.load)
  gfc_list_raster[[i]] <- r
  rm(r)
}
gfc_stack <- rast(gfc_list_raster)

# Align GFC 
gfc_stack_aligned <- project(gfc_stack, reference_sub, method = "near")
extracted <- terra::zonal(gfc_stack_aligned, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
#extracted <- terra::zonal(gfc_stack_aligned, reference_land, fun = mean, na.rm = TRUE, df = TRUE)
head(extracted)

# Format data frame 
df_long <- extracted %>%
  pivot_longer(
    cols = starts_with("GFC_"),
    names_to = "date",
    values_to = "GFC") %>%
  mutate(year = str_extract(date, "\\d{4}") %>% as.integer())

# Add x & y coordinates
coords <- as.data.frame(reference, xy=T)
df_long <- merge(df_long, coords, all.x=T) %>% dplyr::select(-date)

# Fit GAM: smooth in x, y, and year
gam_model <- gam(GFC ~ s(x, y) + s(year), data = df_long)

# Predict for 2000, 2023, and 2024
newdata <- expand.grid(
  cell_ID = unique(df_long$cell_ID),
  year = c(1999, 2000, 2023, 2024)
)
newdata <- merge(newdata, coords, by = "cell_ID", all.x = TRUE)
newdata$GFC <- predict(gam_model, newdata)

df_long_combo <- rbind(df_long, newdata) %>% 
  mutate(year = as.integer(year)) %>% 
  rename(cov_value = GFC) %>% 
  dplyr::select(-c(x,y)) %>% 
  distinct(cell_ID, year, .keep_all = TRUE)

GFC_joined <- df_long_combo %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) 

df_wide <- GFC_joined %>%
  pivot_wider(
    id_cols = cell_ID,
    names_from = period_counter,
    values_from = cov_value
  ) %>%
  arrange(cell_ID) %>%
  dplyr::select(cell_ID, order(as.numeric(names(.)[-1])) + 1) %>% 
  as.matrix()

write.csv(GFC_joined, "../Covariates for modelling/primary_occ_covariates_GFC_sites.csv")
#write.csv(GFC_joined, "primary_occ_covariates_GFC_full.csv")


# Read CROP proportions ---     
crop <- read.csv("crop_proportion_all_years_predicted.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = crop_prop) %>% 
  distinct()

CROP_joined <- crop %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(CROP_joined, "primary_occ_covariates_crop_predicted.csv", row.names=F)


# Read URBAN proportions ---     
urban <- read.csv("urban_proportion_all_years.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = proportion) %>% 
  distinct()

URBAN_joined <- urban %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(URBAN_joined, "primary_occ_covariates_urban.csv", row.names=F)


# propWDPA --- 
wdpa <- read.csv("prop_wdpa_full.csv")

WDPA_joined <- wdpa %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, prop_in_PA) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = prop_in_PA, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

head(WDPA_joined)
write.csv(WDPA_joined, "primary_occ_covariates_wdpa_full.csv", row.names=F)
