
#################################################################################
### Extract static and dynamic covariates #######################################
#################################################################################

# This file contains code to create a preannotated version of the covariates for 
# the occupancy models. The types of covariates are: 

# * site-level covariates (static). Format: cells x 1 column per each covariate;
# * primary period-level covariates (dynamic). Format: cells x periods per each covariate. 
#       Some of these covariates (e.g. year) will have the repeated values in more than 
#       one column

# Run ONCE but note: this extracts values for cell_IDs present in the WI dataset;
# if you add sites to the dataset, you will need to re-extract the covariates 

# set workspace -----------------------------------------------------------------
setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/10x10 km spatial layers")
rm(list=ls()); gc()

library(terra)
library(stringr)
library(raster)
library(dplyr)
library(tidyr)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(arrow)
library(purrr)

# Set up reference raster -----------------------------------------------------

# Load
reference <- rast("raster_100km2_with_cellID.tif")

# Limit to cell_IDs present in dataset 
site_cells <- read.csv("WI_loc_matching_cell_ID.csv") 

# Mask reference raster 
reference_sub <- mask(reference, reference %in% site_cells$cell_ID, maskvalues=F) 

# Static layers ----------------------------------------------------------------

# Read TIF files for static layers 
static_layers <- list(
  road_dist = rast("roads_100km2.tif"),
  elevation = rast("ele_100km2.tif"),
  tri       = rast("tri_100km2.tif"),
  river_dist= rast("riv_100km2.tif"),
  coeff_var = rast("cv_100km2.tif"),
  cities_lg = rast("humacc_large_100km2.tif"),
  cities_md = rast("humacc_medium_100km2.tif"),
  cities_sm = rast("humacc_small_100km2.tif")
)
r_c <- rast(static_layers)

# Extract cell_IDs
extracted <- terra::zonal(r_c, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Save 
write.csv(extracted, "site_level_covariates.csv", row.names = FALSE)

# Dynamic layers ---------------------------------------------------------------

# Create period template 
min_year <- 2000  
max_year <- 2024 
range_year <- c(min_year, max_year)
min_date <- as.Date(paste(range_year[1] - 1, "-12-01", sep = ""))
max_date <- as.Date(paste(range_year[2] + 1, "-03-01", sep = "")) 
start_period <-  seq.Date(min_date, max_date, by =  "91 day") #"3 month"
end_period <-  c(start_period[-1] - 1, NA)

periods <- data.frame(period = paste("Period", seq(1, length(start_period), by = 1), sep = "_"),
                      start_period = start_period, 
                      end_period = end_period) 
periods <- periods[-nrow(periods),]
periods$season <- rep(c("Winter", "Spring", "Summer", "Fall"), length.out = nrow(periods))
periods$year <- year(periods$start_period)
periods$period_counter <- 1:nrow(periods)
head(periods)


## Annual dynamic layers ------------------------------------------------------

# Function to predict CHELSA variables for years between those with values (1999-2010, 2011-2040) with 95% CI 
custom_predict <- function(model, data) {
  if (!inherits(model, "lm")) {
    return(tibble(year = numeric(0),
                  mean_cov = numeric(0),
                  upp_95ci = numeric(0),
                  low_95ci = numeric(0)))
  }
  
  # Detect min and max year from the data used to fit the model
  temp_range <- range(data$year, na.rm = TRUE)
  newdat <- data.frame(year = seq(temp_range[1], temp_range[2], 1))
  
  # Predict with standard error
  preds <- predict(model, newdat, se.fit = TRUE)
  
  newdat <- mutate(newdat,
                   mean_cov = preds$fit,
                   upp_95ci = preds$fit + 1.96 * preds$se.fit,
                   low_95ci = preds$fit - 1.96 * preds$se.fit)
  
  newdat
}

# Read TIF files for ANNUAL PRECIP ---    
r_list <- list(
  precip_1999 = rast("annprec_2010_100km2.tif"),
  precip_2011 = rast("annprec_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Model data for intervening years 
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>% 
  mutate(year = as.numeric(str_remove(year, "precip_"))) %>% 
  group_by(cell_ID) %>% 
  nest() %>% 
  mutate(
    model = map(data, ~{
      df <- .x %>% filter(!is.na(cov))
      if (nrow(df) > 1) lm(cov ~ year, data = df) else NA
    }),
    pred = map2(model, data, ~custom_predict(.x, .y))
  ) %>%
  unnest(pred) %>% 
  ungroup() %>% 
  mutate(cov = mean_cov,
         year = as.numeric(year)) %>% 
  filter(year %in% periods$year) %>% 
  left_join(periods, by = "year", relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Save 
write.csv(cov_df, "primary_occ_covariates_precip.csv", row.names = F)


# Read TIF files for ANNUAL TEMP ---    
r_list <- list(
  temp_1999 = rast("anntemp_2010_100km2.tif"),
  temp_2011 = rast("anntemp_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Model data for intervening years 
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>% 
  mutate(year = as.numeric(str_remove(year, "temp_"))) %>% 
  group_by(cell_ID) %>% 
  nest() %>% 
  mutate(
    model = map(data, ~{
      df <- .x %>% filter(!is.na(cov))
      if (nrow(df) > 1) lm(cov ~ year, data = df) else NA
    }),
    pred = map2(model, data, ~custom_predict(.x, .y))
  ) %>%
  unnest(pred) %>% 
  ungroup() %>% 
  mutate(cov = mean_cov,
         year = as.numeric(year)) %>% 
  filter(year %in% periods$year) %>% 
  left_join(periods, by = "year", relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Save 
write.csv(cov_df, "primary_occ_covariates_temp.csv", row.names = F)


# Read TIF files for SEASONAL PRECIP ---    
r_list <- list(
  precseas_1999 = rast("precseas_2010_100km2.tif"),
  precseas_2011 = rast("precseas_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Model data for intervening years 
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>% 
  mutate(year = as.numeric(str_remove(year, "precseas_"))) %>% 
  group_by(cell_ID) %>% 
  nest() %>% 
  mutate(
    model = map(data, ~{
      df <- .x %>% filter(!is.na(cov))
      if (nrow(df) > 1) lm(cov ~ year, data = df) else NA
    }),
    pred = map2(model, data, ~custom_predict(.x, .y))
  ) %>%
  unnest(pred) %>% 
  ungroup() %>% 
  mutate(cov = mean_cov,
         year = as.numeric(year)) %>% 
  filter(year %in% periods$year) %>% 
  left_join(periods, by = "year", relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Save 
write.csv(cov_df, "primary_occ_covariates_precseas.csv", row.names = F)


# Read TIF files for WARMEST SEASON PRECIP --    
r_list <- list(
  warmseas_1999 = rast("precwarm_2010_100km2.tif"),
  warmseas_2011 = rast("precwarm_2040_100km2.tif")
)
r_stack <- rast(r_list)

# Extract cell_IDs
extracted <- terra::zonal(r_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE) 
head(extracted)

# Model data for intervening years 
cov_df <- extracted %>%
  pivot_longer(-cell_ID, names_to = "year", values_to = "cov") %>% 
  mutate(year = as.numeric(str_remove(year, "warmseas_"))) %>% 
  group_by(cell_ID) %>% 
  nest() %>% 
  mutate(
    model = map(data, ~{
      df <- .x %>% filter(!is.na(cov))
      if (nrow(df) > 1) lm(cov ~ year, data = df) else NA
    }),
    pred = map2(model, data, ~custom_predict(.x, .y))
  ) %>%
  unnest(pred) %>% 
  ungroup() %>% 
  mutate(cov = mean_cov,
         year = as.numeric(year)) %>% 
  filter(year %in% periods$year) %>% 
  left_join(periods, by = "year", relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Save 
write.csv(cov_df, "primary_occ_covariates_warmseas.csv", row.names = F)


# Read TIF files for GWP --- 
gwp_list_raster <- NULL 
gwp <- list.files("GWP")
for(i in 1:length(gwp)){
  file.to.load <- paste0("GWP/",gwp[i]) 
  r <- rast(file.to.load)
  gwp_list_raster[[i]] <- r
  rm(r)
}
gwp_stack <- rast(gwp_list_raster)

# extract mean values for each cell_ID across all rasters in the stack
extracted <- terra::zonal(gwp_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
head(extracted)

# to predict GPW for years between those with values (2000-2005-2010-2020) with 95% CI 
custom_predict <- function(model, temp_range = c(min_year, max_year)) {
  # 95% confidence interval is first calculated on the link scale and then back-transformed:
  
  # build new dataframe
  newdat = data.frame(year = seq(temp_range[1], temp_range[2], 1))
  
  # extract the inverse link function from model
  ilink <- family(model)$linkinv
  # add fit and se.fit on the logit scale
  newdat <- bind_cols(newdat, setNames(as_tibble(predict(model, newdat, se.fit = TRUE)[1:2]),
                                       c('fit_link','se_link')))
  # create the interval and backtransform
  newdat <- mutate(newdat,
                   mean_GPW  = ilink(fit_link),
                   upp_95ci = ilink(fit_link + (1.96 * se_link)),
                   low_95ci = ilink(fit_link - (1.96 * se_link)))
  newdat
}

GPW <- extracted %>%
  pivot_longer(-c(cell_ID), names_to = "year", values_to = "cov") %>% 
  mutate(year = as.numeric(str_remove(year, "GPW_"))) %>% 
  group_by(cell_ID) %>% 
  nest() %>% 
  mutate(
    model = map(data, ~{df <- .x %>% filter(!is.na(cov))
    if (nrow(df) > 1) {
      lm(cov ~ year, data = df)
    } else {NA} #returns NA if not enough data 
    }),
    pred = map(model, ~{
      if (is.list(.x)) {
        custom_predict(.x)
      } else {NA} #returns NA if no model prediction 
    })
  ) %>%
  unnest(pred) %>% 
  ungroup() %>% 
  mutate(cov = mean_GPW,
         year = as.character(year)) %>% 
  mutate(year = as.numeric(year)) %>% 
  filter(year %in% periods$year) %>% 
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Save 
write.csv(GPW, "primary_occ_covariates_GPW.csv", row.names = F)


# Read TIF files for EVI --- 
evi_list_raster <- NULL 
evi <- list.files("EVI")
for(i in 1:length(evi)){
  file.to.load <- paste0("EVI/",evi[i])
  r <- rast(file.to.load)
  evi_list_raster[[i]] <- r
  rm(r)
}
evi_stack <- rast(evi_list_raster)
names(evi_stack) <- gsub('.{11}$', '', evi)

# extract mean values for each cell_ID across all rasters in the stack
extracted <- terra::zonal(evi_stack, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
head(extracted)

# format dataframe 
EVI_long <- extracted %>%
  pivot_longer(cols = starts_with("evi_"),  
               names_to = "covariate",
               values_to = "cov_value") %>%
  mutate(
    year = as.numeric(sub("evi_(\\d{4})_(\\d{3})", "\\1", covariate)),  
    day_of_year = as.numeric(sub("evi_\\d{4}_(\\d{3})", "\\1", covariate)),  
    date = as.Date(paste(year, day_of_year), format = "%Y %j")  
  ) %>% 
  filter(year %in% periods$year) %>% 
  select(c(cell_ID, cov_value, date))

EVI_joined <- EVI_long %>%
  left_join(periods %>% mutate(dummy = 1), by = character()) %>% 
  filter(date >= start_period & date <= end_period) %>% 
  group_by(cell_ID, period_counter) %>% #for when multiple values per cell per period 
  summarise(
    cov_value = mean(cov_value, na.rm = TRUE),
    .groups = "drop"
  )

EVI_mat <- EVI_joined %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(EVI_mat, "primary_occ_covariates_EVI.csv")


# Read TIF files for GFC

# GFC - 2001:2021 
gfc_list_raster <- NULL 
gfc <- list.files("../Raw spatial layers/GFC")
for(i in 1:length(gfc)){
  file.to.load <- paste0("../Raw spatial layers/GFC/",gfc[i])
  r <- rast(file.to.load)
  gfc_list_raster[[i]] <- r
  rm(r)
}
gfc_stack <- rast(gfc_list_raster)

test <- (gfc_stack[[1]])
plot(test)
test <- as.data.frame(gfc_stack[[1]]$GFC_v19_2001_mn_1km) %>%
  filter(across(everything(), ~. != 0))
hist(test$GFC_v19_2001_mn_1km) #compare to 2022:2023
length(unique(test$GFC_v19_2001_mn_1km)) #excluding 9s, 49928237 unique values ... round these? 
# honestly not sure how fabiola ended up with range from 0-10,000: dataset should be 0-22/23... 

gfc_stack_aligned <- project(gfc_stack, reference_sub, method = "near")
extracted <- terra::zonal(gfc_stack_aligned, reference_sub, fun = mean, na.rm = TRUE, df = TRUE)
extracted_scaled <- extracted %>% mutate(across(-cell_ID, ~ round((.x / 10000) * 23))) %>% 
  rename_with(~ sub(".*_(\\d{4})_.*", "\\1", .), -cell_ID)

# add gfc 2022:2023
gfc_2022 <- read.csv("gfc_2022.csv") %>% rename(`2022` = spat_756866bc4e4a6_480902_o8up7yuDdJ6XHBX)
gfc_2023 <- read.csv("gfc_2023.csv") %>% rename(`2023` = spat_1b436fdfa120c_1786735_zxzxx9jyyx6UnnI)
extracted_scaled <- merge(extracted_scaled, gfc_2022, by="cell_ID")
extracted_scaled <- merge(extracted_scaled, gfc_2023, by="cell_ID")

# format dataframe 
GFC_long <- extracted_scaled %>%
  pivot_longer(cols = -cell_ID,
               names_to = "year",
               values_to = "cov_value") %>%
  mutate(year = as.integer(year)) %>% 
  filter(year %in% periods$year) %>% 
  select(c(cell_ID, cov_value, year))

GFC_joined <- GFC_long %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(GFC_joined, "primary_occ_covariates_GFC.csv")


# Read CROP proportions ---     
crop <- read.csv("crop_proportion_all_years.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = proportion) %>% 
  distinct()

CROP_joined <- crop %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(CROP_joined, "primary_occ_covariates_crop.csv", row.names=F)


# Read URBAN proportions ---     
urban <- read.csv("urban_proportion_all_years.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = proportion) %>% 
  distinct()

URBAN_joined <- urban %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(URBAN_joined, "primary_occ_covariates_urban.csv", row.names=F)


# propWDPA --- 
wdpa <- read.csv("wpdf_prop.csv")

WDPA_joined <- wdpa %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, prop_inside) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = prop_inside, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(WDPA_joined, "primary_occ_covariates_wdpa.csv", row.names=F)
