##################################################
###### Covariate Download & Pre-Processing #######
##################################################

# Project: WI Occupancy Range Wide Trends

# This file contains code to download and pre-process, including: 
# 1) Downloading EVI data 
# 2) Aggregating 1km2 products at 10km2 scale 
# Note that calculating proportions of 10km2 cells happens in 02b for WDPA, CCI layers 

# Run 1x
# Note that some data are downloaded manually 


# Set workspace ---------------------------------------------------------------

# Workspace
rm(list=ls()); gc()
setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights")
set.seed(123)

# Libraries 
library(sf)
library(terra)
library(raster)
library(dplyr)
library(modisfast)
library(spData)
library(ggplot2)
library(stringr)


## Bulk download EVI files from EOSDID ----------------------------------------

# Identify data to download --- 
# Login to EOSDIS Earthdata with your username and password  
log <- mf_login(credentials = c("USERNAME", "PASSWORD")) #update with your own 

# Define MODIS collections and variables (bands) of interest
# Run mf_list_collections() for an exhaustive list of collections available
collection <- "MOD13A3.061" 
# Run mf_list_variables("MOD13A3.061") for an exhaustive list of variables available for the collection "MOD13A3.061"
variables <- c("_1_km_monthly_EVI") 

# Run for each country for each year ---
data(world)
countries <- world$name_long

# Set ROI of interest (update manually; easier than looping)
i <-1 
(where <- countries[i])
country <- world[world$name_long == where,]
roi <- st_as_sf(data.frame(id = where, geom = st_as_sfc(st_bbox(country))))
ggplot() + geom_sf(data=roi) + geom_sf(data=country) # quick check

# Loop through years 
for(year in seq(2001,2024)){ 
  
  # Set time frame of interest 
  (start.date <- paste0(year,"-01-01"))
  (end.date <- paste0(year,"-12-31"))
  (time_range <- as.Date(c(start.date, end.date)))
  
  # Get the URLs of the data
  urls <- mf_get_url(
    collection = collection,
    variables = variables,
    roi = roi,
    time_range = time_range)
  
  # Download the data
  res_dl <- mf_download_data(urls, parallel = TRUE)
  
  # Transform to raster 
  r <- mf_import_data(
    path = dirname(res_dl$destfile[1]),
    collection = collection,
    proj_epsg = 4326
  )
  
  # Check and save 
  terra::plot(r, col = rev(terrain.colors(20)))
  (filename <- paste0(where,"_",year,".tif"))
  writeRaster(r, filename)
}


## Aggregate 1km2 data to 10km2 scale -----------------------------------------

# Clear workspace
rm(list=ls()); gc()

# Load 10x10km2 raster grid 
ref_raster <- rast("10x10 km spatial layers/reference_10km2.tif")

# Load data layers 
rasters_paths <- c(
  road_dens  =    "1x1 km spatial layers/road_full_1km2.tif",
  tri        =    "1x1 km spatial layers/tri_1km2_on_ref_grid.tif",
  river_dist =    "1x1 km spatial layers/riv_1km2_on_ref_grid.tif",
  coeff_var  =    "1x1 km spatial layers/cv_1km2_on_ref_grid.tif",
  cities_lg  =    "1x1 km spatial layers/ha_large_1km2_on_ref_grid.tif", 
  ann_temp_2010 = "Raw spatial layers/CHELSA_bio1_1981-2010_v2-1.tif", 
  ann_temp_2040 = "Raw spatial layers/Projected CHELSA/warped_CHELSA_bio1_2011-2040_v2-1.tif", 
  annprec_2010  = "Raw spatial layers/CHELSA_bio12_1981-2010_v2-1.tif", 
  annprec_2040  = "Raw spatial layers/Projected CHELSA/warped_CHELSA_bio12_2011-2040_v2-1.tif", 
  precseas_2010 = "Raw patial layers/Projected CHELSA/warped_CHELSA_bio15_1981-2010_v2-1.tif", 
  precseas_2040 = "Raw spatial layers/Projected CHELSA/warped_CHELSA_bio15_2011-2040_v2-1.tif", 
  precwarm_2010 = "Raw spatial layers/Projected CHELSA/warped_CHELSA_bio18_1981-2010_v2-1.tif", 
  precwarm_2040 = "Raw spatial layers/Projected CHELSA/warped_CHELSA_bio18_2011-2040_v2-1.tif"
)

# Note that:
# - for CHELSA layers (2011-2040), using GFDL-ESM4 model; National Oceanic and Atmospheric Administration, Geophysical Fluid Dynamics Laboratory, Princeton, NJ 08540, USA 
# - CHELSA layers were reprojected using "nearest neighbour", and set to match extent and resolution of reference layers in QGIS
# - for bio15 (seasonal precipitation; 1981-2010), HPC layer threw errors, so redownloaded and processed original data 
# - for bio18 (precipitation in warmest quarter; 1981-2010), no HPC layer, so downloaded and processed 

# Output directory
out_dir <- "10x10 km spatial layers/"

# Function: reproject + resample/aggregate 
aggregate_to_10km <- function(input_path, layer_name, target_raster, out_dir, fun = "mean") {
  
  # Map fun to resampling method (extend as needed for other fun types)
  resamp_method <- ifelse(fun == "mean", "average", "near") 
  
  # Load raster
  r <- rast(input_path)
  
  # Reproject to target CRS if mismatched (keep fine resolution)
  if (crs(r) != crs(target_raster)) {
    message("CRS mismatch for ", basename(input_path), " — reprojecting to target CRS at fine resolution")
    r <- project(r, crs(target_raster), method = "bilinear")  
  }
  
  # Resample to target grid (means)
  r_agg <- resample(r, target_raster, method = resamp_method, threads = TRUE)
  
  # Rename
  new_name <- paste0(layer_name, "_10km")
  names(r_agg) <- new_name
  
  # Save
  out_file <- file.path(out_dir, paste0(new_name, ".tif"))
  writeRaster(r_agg, out_file,
              overwrite = TRUE,
              datatype = "FLT4S",
              gdal = c("COMPRESS=DEFLATE", "PREDICTOR=2", "ZLEVEL=9"))
  
  message("Saved: ", out_file, " (layer: ", new_name, ")")
  rm(r, r_agg); gc()
  
  return(out_file)   
}

# Run on all files and collect output paths
out_files <- Map(
  aggregate_to_10km,
  input_path = rasters_paths,
  layer_name = names(rasters_paths),
  MoreArgs = list(target_raster = ref_raster, out_dir = out_dir)
)

# For rasters with >1 layer -- 

rasters_paths <- c(gwp ="Raw spatial layers/gpw_v4_PopDensity_rev11.tif")

# Function: reproject + resample/aggregate 
aggregate_to_10km_MANY <- function(input_path, layer_name, target_raster, out_dir, fun = "mean") {
  
  resamp_method <- ifelse(fun == "mean", "average", "near") 
  r <- rast(input_path)
  if (crs(r) != crs(target_raster)) {
    message("CRS mismatch for ", basename(input_path), 
            " — reprojecting to target CRS at fine resolution")
    r <- project(r, crs(target_raster), method = "bilinear")  
  }
  r_agg <- resample(r, target_raster, method = resamp_method, threads = TRUE)
  new_name <- paste0(layer_name, "_10km")
  out_file <- file.path(out_dir, paste0(new_name, ".tif"))
  writeRaster(r_agg, out_file,
              overwrite = TRUE,
              datatype = "FLT4S",
              gdal = c("COMPRESS=DEFLATE", "PREDICTOR=2", "ZLEVEL=9"))
  
  message("Saved: ", out_file, " (layer: ", new_name, ")")
  rm(r, r_agg); gc()
  return(out_file)   
}

# Run on all files and collect output paths
out_files <- Map(
  aggregate_to_10km_MANY,
  input_path = rasters_paths,
  layer_name = names(rasters_paths),
  MoreArgs = list(target_raster = ref_raster, out_dir = out_dir)
)

# For rasters with >1 layer -- 
evi_files <- list.files("Raw spatial layers/EVI 1km2", full.names = TRUE)
evi_list_raster <- lapply(evi_files, rast)
out_dir <- "10x10 km spatial layers/EVI"

for(i in 1:length(evi_list_raster, target_raster)){
  
  evi_file <- evi_list_raster[i]
  evi_10km <- resample(evi_file, target_raster, method = "mean")
  
  # Keep original layer names  
  names(evi_10km) <- names(names(evi_file[[1]]))
  
  # Output path
  out_file <- file.path(out_dir, out_filename)
  
  # Write with good compression
  gdal_opts <- c("COMPRESS=DEFLATE", "PREDICTOR=2", "ZLEVEL=9")
  if (!compress) gdal_opts <- NULL
  
  writeRaster(evi_10km,
              filename = out_file,
              overwrite = TRUE,
              datatype = "FLT4S",
              gdal = gdal_opts,
              progress = 1)
  
  # Clean up
  rm(evi_10km); gc()
  return(out_file)
}


## Aggregate 1km2 data to 10km2 scale: PROPORTION DATA ------------------------

# Clear workspace
rm(list=ls()); gc()

# Load 10x10km2 raster grid 
ref_raster <- rast("10x10 km spatial layers/reference_10km2.tif")


## WDPA --- 
wdpa <- rbind(st_read("Raw spatial layers/WDPA_Jan2025_Public_shp/WDPA_Jan2025_Public_shp_0/WDPA_Jan2025_Public_shp-polygons.shp"),
              st_read("Raw spatial layers/WDPA_Jan2025_Public_shp/WDPA_Jan2025_Public_shp_1/WDPA_Jan2025_Public_shp-polygons.shp"),
              st_read("Raw spatial layers/WDPA_Jan2025_Public_shp/WDPA_Jan2025_Public_shp_2/WDPA_Jan2025_Public_shp-polygons.shp"))

# Ensure CRS match
if (st_crs(wdpa) != crs(ref_raster)) {
  wdpa <- st_transform(wdpa, crs(ref_raster))
}

# Repair geometries 
wdpa <- st_make_valid(wdpa)

# Polygon of only non-NA cells
mask_poly <- st_as_sf(as.polygons(!is.na(ref_raster), na.rm = TRUE, dissolve = TRUE))

# Intersect WDPA with the actual non-NA footprint
wdpa_aoi_sf <- suppressWarnings(st_intersection(wdpa, mask_poly))

# Clean up
wdpa_aoi_sf <- st_make_valid(wdpa_aoi_sf)
wdpa_aoi_sf <- wdpa_aoi_sf[!st_is_empty(wdpa_aoi_sf), ]
cat("Number of valid PAs overlapping non-NA cells of reference raster:", nrow(wdpa_aoi_sf), "\n")

# Convert to SpatVector  
wdpa_aoi_vect <- vect(wdpa_aoi_sf)

# Quick save: 
writeVector(wdpa_aoi_vect, "wdpa_aoi_global.gpkg", overwrite = TRUE)

# Get unique years 
unique_years <- 2000:2024

# Create time-varying PA masks
pa_layers <- list()
for (yr in unique_years) {
  
  # Select PAs designated on or before this year
  wdpa_year_vect <- wdpa_aoi_vect[wdpa_aoi_vect$STATUS_YR <= yr, ]
  
  # Rasterize binary (1 = protected that year, background = NA for unprotected)
  if (nrow(wdpa_year_vect) == 0) {
    pa_year <- ref_raster 
    pa_year[!is.na(pa_year)] <- NA
  } else {
    pa_year <- rasterize(wdpa_year_vect, ref_raster, field = 1, background = NA)
  }
  names(pa_year) <- paste0("protected_", yr)
  pa_layers[[as.character(yr)]] <- pa_year
}
pa_stack <- rast(pa_layers)

# Add cell_ID layer
cell_id_species <- crop(global_cell_id, ref_raster)
full_stack_pa <- c(cell_id_species, pa_stack)

# Data frame
pa_df_wide <- as.data.frame(full_stack_pa, na.rm = FALSE, xy = TRUE)
names(pa_df_wide) <- c("x", "y", "cell_ID", paste0("protected_", unique_years))
prot_cols <- paste0("protected_", unique_years)
pa_df_wide[, prot_cols] <- lapply(pa_df_wide[, prot_cols], function(col) ifelse(is.na(col), 0, col))
pa_df_wide <- pa_df_wide[!is.na(pa_df_wide$cell_ID), ]

# Melt to long format
setDT(pa_df_wide)
pa_df_long <- melt(pa_df_wide,
                   id.vars = c("x", "y", "cell_ID"),
                   measure.vars = prot_cols,
                   variable.name = "year_var",
                   value.name = "protected")

# Extract year as integer
setDT(pa_df_long)
pa_df_long[, year := as.integer(sub("protected_", "", year_var))]
pa_df_long[, year_var := NULL]

# Aggregate to proportion per cell_ID and year
wdpa_agg <- pa_df_long[, .(proportion = mean(protected)), by = .(cell_ID, year)]

# Expand to period_counter
wdpa_data <- periods[, .(year, period_counter)][wdpa_agg, on = "year", allow.cartesian = TRUE]
wdpa_data <- wdpa_data[, .(cell_ID, year, proportion, period_counter)]
setorder(wdpa_data, cell_ID, year, period_counter)
#wdpa_data <- wdpa_agg
head(wdpa_data)
