## Cleaning raw image and sequence data from Wildlife Insights 
## Wildlife Insights private and public records data downloaded 04 Sep 2024 

######################################################################################
##### SEQUENCES ######################################################################
######################################################################################

rm(list=ls()); gc()
setwd("~/project/WI_2024")

# Load libraries ---------------------------------------------------------------------

library(tidyverse)
library(stringr)
library(lubridate)
library(data.table)
library(tibble)
library(CoordinateCleaner)
library(dplyr)
library(ggmap)
library(arrow)

# Load  and filter data ----------------------------------------------------------------

# Private project IDs to exclude 
rm_project_id <- c(2007556, 2007371, 2006485, 2006885, 2006031, 2003854, 2004980, 2006913)

# Project status 
status <- read.csv("20240904_project_status_WI.csv")

# Sequence data 
sequence <- read.delim("20240904_sequence_science_vw_all_ids_with_time_lag_20240904.txt") 
nrow(sequence) #4352839

# Remove private projects
sequence <- sequence %>% filter(!project_id %in% rm_project_id)
nrow(sequence) #4350128
head(sequence) 

# Fix shifted columns --------------------------------------------------------------------

# Examine data 
shifted_seqs <- setdiff(unique(sequence$taxonomy_subtype), c("wild-animal", "human", "admin", "domestic-animal", "object", "physical", "wild animal", ""))
sub <- sequence %>% filter(taxonomy_subtype %in% shifted_seqs)
View(sub) #all original columns shifted by one, starting from "deployment_name" 

# Fix for general shifted columns 
sub_cols <- names(sub)
sub$deployment_name <- NULL
sub <- as.data.frame(append(sub, list(ageinmin = NA), after = 50))
names(sub) <- sub_cols
View(sub) #overall, fixed; still need to fix shifted rows in last project ("Chances for Nature")  

# Additional fix for specific organization 
sub1 <- sub %>% filter(organization_name == "Chances for Nature")
sub1 <- sub1 %>%
  mutate(
    deployment_location_id = longitude,
    longitude = latitude,
    latitude = deployment_id
  )
sub <- sub %>% filter(organization_name != "Chances for Nature")
sub <- bind_rows(sub, sub1)
rm(sub1)

# Combine fixed sequences back 
sequence <- sequence %>% filter(!taxonomy_subtype %in% shifted_seqs)
sequence <- bind_rows(sequence, sub)
nrow(sequence) #4350128
unique(sequence$taxonomy_subtype)

# Examine columns with "" as taxonomy 
sub <- sequence[sequence$taxonomy_subtype == "",]
View(sub) #oh boy, lots going on here  

# Remove rows with incomplete metadata 
View(sequence[sequence$organization_id == "None",]) #can't save 
View(sequence[sequence$id == "wild-animal",]) #can't save
View(sequence[sequence$u_id == 0,]) #can't save
View(sequence[sequence$year == "",])

sequence <- sequence %>%
  filter(
    organization_id != "None",
    id != "wild-animal",
    u_id != 0,
    year != ""
  )

sub <- sequnce %>% filter(taxonomy_subtype == "") #double-check fixed
View(sub) #seems okay now 
rm(sub)

# Format columns -------------------------------------------------------------------------

sequence <- sequence %>%
  mutate(
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude),
    sequence_date = as.Date(sequence_date, "%Y-%m-%d"),
    sequence_datetime = as.POSIXct(sequence_datetime, "%Y-%m-%d %H:%M:%S")
  )
nrow(sequence) #4348102

# Select data of interest ----------------------------------------------------------------

# Filter by class
unique(sequence$class)  
check <- sequence[sequence$class == "",] #what are these? 
unique(check$common_name_english) #can ignore 
check <- sequence[is.na(sequence$class),] #what are these? 
unique(check$common_name_english) #these are all wild-animals

sequence <- sequence %>% filter(class %in% c("Mammalia", "Aves"))
nrow(sequence) #3879253

# Filter by/fix taxonomy subtype lables 
unique(sequence$taxonomy_subtype)
check <- sequence[sequence$taxonomy_subtype == "",] #what are these? 
unique(check$common_name_english) #these are all wild-animals 
sequence[sequence$taxonomy_subtype == "",]$taxonomy_subtype <- "wild-animal"

sequence <- sequence %>%
  filter(taxonomy_subtype %in% c("wild-animal", "wild animal")) %>%
  mutate(taxonomy_subtype = "wild-animal")
nrow(sequence) #2944384

# Extract and clean project metadata ----------------------------------------------------- 

# Extract metadata 
project_data <- sequence %>% select(project_metadata) 
project_data$project_metadata <- str_replace_all(project_data$project_metadata, "[{}]", "")
project_data <- cbind(sequence$project_id, project_data)

project_data_raw <- sequence %>%
  select(project_id, project_metadata) %>%
  distinct() %>%
  mutate(project_metadata = str_replace_all(project_metadata, "[{}]", ""))

# Separate metadata into columns 
proj_id_df <- project_data_raw %>% select(project_id)
metadata_split <- str_split_fixed(project_data_raw$project_metadata, ",", Inf)
project_data <- as.data.frame(metadata_split)
project_data <- bind_cols(proj_id_df, project_data)
nrow(project_data) #568
head(project_data)

# Some problematic rows: issues caused by data containing commas while delineated by commas 
(to_fix <- project_data %>% filter(V18 != "")) #3 rows with issues 

# -> For now, remove data that does not contain ":" and add back in to_fix df manually 
project_data <- project_data %>% filter(!project_id %in% to_fix$project_id)

# Set up metadata dataframe 
metadata_cols <- c(
  "project_id", "country_code", "project_admin", "project_species", "project_bait_use",
  "project_bait_type", "project_admin_email", "project_blank_images", "project_sensor_layout",
  "project_sensor_method", "project_sensor_cluser", "project_stratification", 
  "project_individual_animals"
)
project_metadata <- as.data.frame(matrix(ncol = length(metadata_cols), nrow = 0))
colnames(project_metadata) <- metadata_cols

# Fix known text issues in metadata (trailing backslashes) 
project_data$V17[33] <- "Negev Highlands and Hyper Arid South (Arava Valley)"
project_data$V13[405] <- "project_stratification_type: 3x condition (good)"
project_data$V15[405] <- "(poor) and 2x predicted importance for connectivity (yes)"
project_data$V17[481]  <- "Negev Highlands and Hyper Arid South (Arava Valley)"

# Parse metadata 
for(i in 1:nrow(project_data)){
  sub <- project_data[i,]
  sub <- sub[nzchar(sub)] #removes surrounding ""
  project_metadata[i,1] <- as.character(sub[1,1])
  for(j in 2:length(sub)){
    x <- trimws(strsplit(as.character(sub[j]), "[:]")[[1]][1])
    y <- trimws(strsplit(as.character(sub[j]), "[:]")[[1]][2])
    cols <- grep(x, names(project_metadata))
    project_metadata[i,cols] <- y
  }
}
head(project_metadata)

# Add manually fixed rows (** make more elegant later) 
View(to_fix)
to_fix_df <- data.frame('project_id' = c("2004352", "2006613", "2006613"),
                        'country_code' = c("USA", "USA", "USA"), 
                        'project_admin' = c("ryan.peek@wildlife.ca.gov", "Glen Kalisz", "Glen Kalisz"), 
                        'project_species' = c("Multiple", "Multiple", "Multiple"), 
                        'project_bait_use' = c("No", "No", "No"),
                        'project_bait_type' = c("None", "None", "None"), 
                        'project_admin_email' = c("ryan.peek@wildlife.ca.gov", "kalisgl@wsdot.wa.gov", "glen.kalisz@wsdot.wa.gov"), 
                        'project_blank_images' = c("Yes", "Some", "Some"), 
                        'project_sensor_layout' = c("Targeted", "Targeted", "Targeted"), 
                        'project_sensor_method' = c("Time lapse", "Sensor detection", "Sensor detection"), 
                        'project_sensor_cluser' = c("No", "No", "No"), 
                        'project_stratification' = c("No", "Interstate right of way", "Interstate right of way"), 
                        'project_individual_animals' = c("Time lapse locations", "Bridge crossings", "Bridge crossing"))

project_metadata <- bind_rows(project_metadata, to_fix_df) %> left_join(status, by = "project_id")

# Clean workspace 
rm(proj_id); rm(project_data); rm(sub); rm(to_fix); rm(to_fix_df)

# Combine with sequence data ------------------------------------------------------------- 
sequence <- sequence %>% 
  mutate(
    latitude_fix = latitude,
    longitude_fix = longitude,
    sequence_date_fix = sequence_date,
    sequence_datetime_fix = sequence_datetime
  ) %>%
  left_join(project_metadata, by = "project_id")
head(sequence) 

# Remove records without species binomial -------------------------------------------------

# Check data 
sum(is.na(sequence$sp_binomial)) #no "NA" sp binomials 

nrow(sequence[sequence$sp_binomial == "",]) #433528 blank species binomials 
head(sequence[sequence$sp_binomial == "",]); tail(sequence[sequence$sp_binomial == "",])
unique(sequence[sequence$sp_binomial == "",]$common_name_english) #not id'ed to genus
sequence <- sequence %>% filter(sp_binomial != "") #remove for now  
nrow(sequence) #2514306

# Remove "test" or "demo" projects --------------------------------------------------------

# What site names contain words "test" or "demo"? 
sequence$site_name_testordemo <- tolower(sequence$site_name)
sequence$site_name_testordemo <- ifelse(grepl("test", sequence$site_name_testordemo), "test", 
                                        ifelse(grepl("demo", sequence$site_name_testordemo), 
                                               "demo", "fine"))
testordemo <- sequence[sequence$site_name_testordemo %in% c("test","demo"),]
unique(testordemo$site_name) 

# How many entries per project? Assume demos small 
table(testordemo$site_name) 

# Examine these further (>500 images uploaded )
head(sequence[sequence$site_name == "Wildlife Camera Project - Test Project (Sequence)",]) #fine
head(sequence[sequence$site_name == "Wildlife Camera Project - Pilot Study 2022 - Test 1 (Sequence)",]) #fine
head(sequence[sequence$site_name == "SCBI Testing Grid",]) #fine
fine <- c("SCBI Testing Grid", "Wildlife Camera Project - Pilot Study 2022 - Test 1 (Sequence)", "Wildlife Camera Project - Test Project (Sequence)")

# Remove test/demo sites 
testordemo <- testordemo[!testordemo$site_name %in% fine,]
sequence <- sequence[!sequence$site_name %in% testordemo$site_name,]
nrow(sequence) #2514137
rm(testordemo)

# Spatial fixes ---------------------------------------------------------------------------

# Check coordinate ranges 
range(sequence$longitude_fix) #should be -180 to 180; looks okay 
range(sequence$latitude_fix) #should be -90 to 90; looks okay 

# Examine 0,0 coordinates 
nrow(sub <- sequence[sequence$longitude_fix == 0 & sequence$latitude_fix == 0,])
unique(sub$organization_name) #2 organizations 
View(sub) #no other coordinate info anywhere else in dataframe 
sequence <- sequence %>% filter(!(longitude_fix == 0 & latitude_fix == 0)
nrow(sequence) #2509496

# Flag records over water 
sequence$over_water <- CoordinateCleaner::cc_sea(sequence, lon = "longitude_fix", lat = "latitude_fix", value = "flagged")
nrow(sub <- sequence %>% filter(over_water == "FALSE")) #FALSE = water images 

# Exclude sites clearly coastal or islands (CoordinateCleaner has margin of error, often flags near-water sites as water)
unique(sub$site_name) 
coastal_sites <- c("Florida Keys Inventory and Monitoring", "The Nature Conservancy's Virginia Coast Reserve", "Crocodile Lake Inventory and Monitoring Project", "California Coast Coyote Project", "Point Reyes Beach Cameras")
sub <- sub %>% filter(!site_name %in% coastal_sites)
unique(sub$site_name)
rm(coastal_sites)

# Manually review other water record sites 
head(sub[sub$site_name == "Season 2020/21",]) #on the coast; fine
head(sub[sub$site_name == "Season 2013/14",]) #on the coast; fine
head(sub[sub$site_name == "Season 2014/2015",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot Europe 2021",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot USA 2021",]) #on the coast; fine
head(sub[sub$site_name == "Panama: Ticks & Climate Change",]) #on the coast; fine
head(sub[sub$site_name == "Coyotes de La Colorada project",]) #on the coast; fine
head(sub[sub$site_name == "ERICA_WP3_2021",]) #on the coast; fine
head(sub[sub$site_name == "Seattle Urban Mesocarnivore Project (2015-2017)",]) #on the coast; fine
head(sub[sub$site_name == "Seattle Urban Carnivore Project",]) #on the coast; fine
head(sub[sub$site_name == "K'gari Potoroo survey",]) #on the coast; fine
head(sub[sub$site_name == "Okaloosa S.C.I.E.N.C.E. Project",]) #on the coast; fine
head(sub[sub$site_name == "Urban to Wild Project",]) #on the coast; fine
head(sub[sub$site_name == "ERICA_WP3_2022",]) #on the coast; fine
head(sub[sub$site_name == "WildTracker Tasmania Project",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot Europe 2022",]) #on the coast; fine
head(sub[sub$site_name == "North Carolina's Candid Critters Project",]) #on the coast; fine
head(sub[sub$site_name == "RVSPAB Pedasi",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot USA 2020",]) #on the coast; fine
head(sub[sub$site_name == "Milfontes",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot USA 2023",]) #on the coast; fine
head(sub[sub$site_name == "Olympic Marten Project",]) #on the coast; fine
head(sub[sub$site_name == "Biodiversidad de manglares de Yucatán",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot Japan 2023",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot Europe 2023",]) #on the coast; fine
head(sub[sub$site_name == "Pepperdine University Biodiversity Snapshot",]) #on the coast; fine
head(sub[sub$site_name == "Scalable biodiversity monitoring research in Azuero Peninsula",]) #on the coast; fine
head(sub[sub$site_name == "NYMS Bucket Cameras",]) #on the coast; fine
head(sub[sub$site_name == "Panamá Pacifico  ",]) #on the coast; fine
head(sub[sub$site_name == "Snapshot USA 2022",]) #on the coast; fine

# -> Latitude should be negative 
head(sub[sub$site_name == "Bulk upload trial - Home sites",]) 
head(sub[sub$site_name == "Monitoring arboreal mammals and birds using nestboxes",])  
to_fix_lat <- c("Bulk upload trial - Home sites", "Monitoring arboreal mammals and birds using nestboxes")

# -> Longitude should be negative 
head(sub[sub$site_name == "Princeton ",]) #LONG SHOULD BE NEGATIVE 
head(sub[sub$site_name == "SEGUIMIENTO CARNIVOROS",]) #LONG SHOULD BE NEG
to_fix_long <- c("Princeton ", "SEGUIMIENTO CARNIVOROS")

# -> Longitude two decimal places off 
head(sub[sub$site_name == "Project Create via API_d",])  
to_fix_decimal <- "Project Create via API_d"

# -> Latitude and longitude flipped 
head(sub[sub$site_name == "Hamaarag long term monitoring T4 2021-2022",])  
to_fix_flipped <- "Hamaarag long term monitoring T4 2021-2022"

# -> Cannot fix, delete 
head(sub[sub$site_name == "Barren Grounds quolls",]) 
head(sub[sub$site_name == "PNAE_22",])  
head(sub[sub$site_name == "Dulci_sequence",])  
to_delete <- c("Barren Grounds quolls", "PNAE_22", "Dulci_sequence")

# Fix issues

# -> Delete problematic sites  
sequence <- sequence %>% filter(!(site_name %in% to_delete & over_water == "FALSE"))

# -> Negate latitude 
sequence <- sequence %>%
  mutate(latitude_fix = ifelse(site_name %in% to_fix_lat & over_water == "FALSE" & latitude_fix > 0, -latitude_fix, latitude_fix))

# -> Negate longitude 
sequence <- sequence %>%
  mutate(longitude_fix = ifelse(site_name %in% to_fix_long & over_water == "FALSE" & longitude_fix > 0, -longitude_fix, longitude_fix))

# -> Decimal shift fix 
sequence <- sequence %>%
  mutate(longitude_fix = ifelse(site_name %in% to_fix_decimal & over_water == "FALSE", longitude_fix / 100, longitude_fix))

# -> Flip lat/long 
flip_idx <- which(sequence$site_name %in% to_fix_flipped & sequence$over_water == "FALSE")
tmp_lat <- sequence$latitude_fix[flip_idx]
tmp_long <- sequence$longitude_fix[flip_idx]
sequence$latitude_fix[flip_idx] <- tmp_long
sequence$longitude_fix[flip_idx] <- tmp_lat

check <- sequence[sequence$site_name %in% to_fix_flipped,] %>% # check if others in set are broken
  select(c(site_name, latitude_fix, longitude_fix)) %>% 
  distinct(.keep_all = TRUE)
View(check) #rest look good EXCEPT where longitude_fix == 0.09253814
sequence <- sequence %>% filter(!(site_name %in% to_fix_flipped & longitude_fix == 0.09253814)) #remove rows with bad flipped coordinates

# Clean workspace 
rm(to_delete); rm(to_fix_lat); rm(to_fix_long); rm(to_fix_decimal); rm(tmp_lat); rm(tmp_long); rm(to_fix_flipped); rm(check)

# Temporal fixes --------------------------------------------------------------------------

# Examine weird dates 
sum(is.na(sequence$sequence_date_fix)) #0 records 
sum(is.na(sequence$sequence_datetime_fix)) #339 records 

# Fix missing datetimes 
sequence$sequence_datetime_fix <- as.character(sequence$sequence_datetime_fix)
missing_dt <- sequence %>% filter(is.na(sequence_datetime_fix))
View(missing_dt) #dates and times both present; some not merged into datetime
missing_dt <- missing_dt %>% mutate(sequence_datetime_fix = paste(sequence_date, sequence_time))
sum(is.na(missing_dt$sequence_datetime_fix)) #0 records
View(sub)

sequence <- sequence %>% filter(!is.na(sequence_datetime_fix))
sequence <- rbind_rows(sequence, missing_dt)
sum(is.na(sequence$sequence_datetime_fix)) #still 110 records 

# Fix obviously wrong years 
unique(sequence$sequence_date)

# -> Some clearly mean to be 2017
sequence[sequence$year == 2701,]
sequence[sequence$unique_id %in% c(20779195:20779205),] 
sequence <- sequence %>%
  mutate(
    sequence_date_fix = ifelse(year == 2701, "2017-11-18", sequence_date_fix),
    sequence_datetime_fix = ifelse(year == 2701, "2017-11-18 10:21:00", sequence_datetime_fix),
    year = ifelse(year == 2701, "2017", year))

# -> 2026: Shifted two years 
sub <- sequence[(sequence$year == 2026) & (sequence$site_name %in% c("Corredor Protección del Jaguar", "McDowell Sonoran Conservancy - Wildlife Camera Project ")),] 
sequence <- sequence %>%
  mutate(
    sequence_date_fix = ifelse(year == 2026 & site_name %in% c("Corredor Protección del Jaguar", "McDowell Sonoran Conservancy - Wildlife Camera Project "), as.character(as.Date(sequence_date_fix) - years(2)), sequence_date_fix),
    sequence_datetime_fix = ifelse(year == 2026 & site_name %in% c("Corredor Protección del Jaguar", "McDowell Sonoran Conservancy - Wildlife Camera Project "), as.character(ymd_hms(sequence_datetime_fix) - years(2)), sequence_datetime_fix)) %>%
  mutate(year = ifelse(year == 2026 & site_name %in% c("Corredor Protección del Jaguar", "McDowell Sonoran Conservancy - Wildlife Camera Project "), year(as.Date(sequence_date_fix)), year))

# -> 2025: Shifted two years 
sub <- sequence[(sequence$year == 2025) & (sequence$site_name %in% c("Corredor Protección del Jaguar", "Corredor Guaviare Meta 2023I")),] 
sequence <- sequence %>%
  mutate(
    sequence_date_fix = ifelse(year == 2025 & site_name %in% c("Corredor Protección del Jaguar", "Corredor Guaviare Meta 2023I"), as.character(as.Date(sequence_date_fix) - years(2)), sequence_date_fix),
    sequence_datetime_fix = ifelse(year == 2025 & site_name %in% c("Corredor Protección del Jaguar", "Corredor Guaviare Meta 2023I"), as.character(ymd_hms(sequence_datetime_fix) - years(2)), sequence_datetime_fix)) %>%
  mutate(year = ifelse(year == 2025 & site_name %in% c("Corredor Protección del Jaguar", "Corredor Guaviare Meta 2023I"), year(as.Date(sequence_date_fix)), year))

# -> Manually evaluated the following dates; deployment years can be derived, BUT month/day of images did not fall within sensor start/stop range; many note camera failure; unable to reconstruct original date
bad_years <- c(2106, 2065, 2036, 2037, 2033, 2032, 2031, 2030, 2028, 2027, 2026, 1976, 1999, 1970)
sequence <- sequence %>% filter(!year %in% bad_years)

# -> 2024: Fix 2024 entries with months > August
sequence$month <- as.numeric(sequence$month)
sub <- sequence[sequence$year == 2024 & sequence$month > 8,] #can't be greater than september -> these one year off 
sequence <- sequence %>%
  mutate(
    year = ifelse(year == 2024 & as.numeric(month) > 8, 2023, year),
    sequence_date_fix = ifelse(year == 2023 & as.numeric(month) > 8,
                               as.character(as.Date(sequence_date_fix) - years(1)),
                               sequence_date_fix),
    sequence_datetime_fix = ifelse(year == 2023 & as.numeric(month) > 8,
                                   as.character(ymd_hms(sequence_datetime_fix) - years(1)),
                                   sequence_datetime_fix))

nrow(sequence) #2510901

# Check times -----------------------------------------------------------------------------

sum(is.na(sequence$sequence_time)) #0
head(sub <- (sequence[sequence$sequence_time == "00:00:00",])); nrow(sub) #201
table(sub$site_name) #nothing looks unreasonable 

# Other checks ----------------------------------------------------------------------------

sum(is.na(sequence$unique_id)) #0
unique(sequence$camera_notes) #looks fine
sort(unique(sequence$site_name)) #nothing looks too suspicious 

sort(unique(sequence$organization_name))
head(sequence[sequence$organization_name == "A Wildlife Organization",]) #seems real enough
head(sequence[sequence$organization_name == "xxx",]) #data seems okay

# Clean up columns ------------------------------------------------------------------------

sequence <- sequence %>% select(-c(latitude, longitude, over_water, site_name_testordemo))

# Flag spatiotemporal duplicates ----------------------------------------------------------

sequence$sequence_datetime <- as.character(sequence$sequence_datetime)
sequence$sequence_date_fix <- as.character(sequence$sequence_date_fix)
sequence.dt <- data.table(sequence)
sequence.dt$spatiotemp_duplicates <- duplicated(sequence.dt[, c("sp_binomial", "longitude_fix", "latitude_fix", "sequence_datetime_fix"),])
nrow(sequence.dt[sequence.dt$spatiotemp_duplicates == TRUE,]) #104021

# Examine where coming from 
head(sub <- sequence.dt[sequence.dt$spatiotemp_duplicates == TRUE,])
unique(sub$site_name) #>200 sites 
sequence[sequence$sp_binomial == "Odocoileus hemionus" & sequence$sequence_datetime == "2014-04-24 18:05:01",] #appear to be multiple images in a sequence? 
sequence[sequence$sp_binomial == "Odocoileus virginianus" & sequence$sequence_datetime == "2017-07-30 05:08:46",] #test another... another genuine duplicate 

# Remove duplicated frows 
sequence.dt <- sequence.dt[!sequence.dt$spatiotemp_duplicates == TRUE,]
sequence <- as.data.frame(sequence.dt)
sequence$spatiotemp_duplicates <- NULL
head(sequence)
rm(sequence.dt)

# Taxonomic harmonization -----------------------------------------------------------------

# Load taxonomies 
birds <- read.csv("~/Desktop/Work/Yale/Data/Harmonization/Birds_WI_to_MOL_harmonized_20220725.csv")
mamms <- read.csv("~/Desktop/Work/Yale/Data/Harmonization/Mammals_WI_to_MOL_harmonized_20220725.csv")
taxa <- rbind(birds, mamms) %>% select(commonNameEnglish, wi_taxon_id, sp_binomial, Accepted_MOL)
rm(mamms, birds)

# Join main data with taxonomy 
sequence <- plyr::join(sequence, taxa, by="wi_taxon_id", type="left")

# Identify unmatched taxonomies 
sum(is.na(sequence$Accepted_MOL)) #2718 without MOL taxonomy match 
missing_mol <- sequence %>% filter(is.na(Accepted_MOL)) %> select(1:68)
unique(missing_mol$common_name_english)

# Try matching by sp_binomial 
missing_mol <- missing_mol %>% left_join(taxa, by = "sp_binomial")
sum(is.na(sub$Accepted_MOL))

# Check remaining unmatched 
unmatched_binom <- missing_mol %>% filter(is.na(Accepted_MOL)) %> pull(sp_binomial) %>% unique()

# Load full MOL taxonomy 
full_mol <- read.csv("~/Desktop/Work/Yale/Data/Harmonization/WI_harmonized_taxonomy_11_2022.csv")
names(full_mol)[5] <- "sp_binomial"

setdiff(sp_binom, unique(full.mol$Accepted)) #7
setdiff(sp_binom, unique(full.mol$canonical)) #6

# Try matching by sp_binomial from full MOL 
missing_mol <- missing_mol %>% left_join(full_mol, by = "sp_binomial")
nrow(sub.1[!is.na(missing_mol.1$Accepted),]) #doing again by 'Accepted' does not help 

# Separate rows matched successfully
matched_v2 <- missing_mol %>% filter(!is.na(Accepted))
matched_v2 <- matched_v2 %>% select(1:68, Accepted) %>% rename(Accepted_MOL = Accepted)

# Combine all matched
sequence <- sequence %>% filter(!is.na(Accepted_MOL)) %>% select(1:68, Accepted_MOL)
sequence <- bind_rows(sequence, matched_v2)

# Remaining unmatched
still_unmatched <- missing_mol %>% filter(is.na(Accepted)) %>% select(1:68)

# Load alternative MOL  taxonomy 
mol_mamms <- read.csv("~/Desktop/Work/Yale/Data/Harmonization/MOL_MammaliaTaxonomy_v2.3_complete_noamb.csv")
#birds <- read.csv("~/Desktop/Work/Yale/Data/Harmonization/MOL_AvesTaxonomy_v2.3_complete_noamb.csv")
mol_mamms <- mol_mamms %>% filter(valid == TRUE)
names(mol_mamms)[3] <- "sp_binomial"
setdiff(unique(still_unmatched.2$sp_binomial), unique(mol_mamms$canonical)) #4

# Join on species binomial 
still_unmatched <- still_unmatched %>% left_join(mol_mamms, by = "sp_binomial")
nrow(still_unmatched.2[is.na(still_unmatched.2$valid),]) #still 446 unmatched observations 

# Separate rows that matched
matched_v3 <- still_unmatched %>%
  filter(!is.na(valid)) %>%
  select(1:68, genus, species) %>%
  mutate(Accepted_MOL = paste(genus, species))

# Rows that remain unmatched after final attempt
final_unmatched <- still_unmatched %>% filter(is.na(valid))

# For remaining rows, if genus/species present, construct Accepted_MOL
if ("genus" %in% names(final_unmatched) & "species" %in% names(final_unmatched)) {
  final_unmatched <- final_unmatched %>%
    filter(!is.na(genus) & !is.na(species)) %>%
    mutate(Accepted_MOL = paste(genus, species))
}

# Combine all and clean
sequence <- bind_rows(sequence, matched_v3, final_unmatched)
sequence <- sequence %>% 
  select(-c(sp_binomial.1)) %>%
  mutate(
    sequence_date_fix = ymd(sequence_date_fix),
    sensor_start_date_and_time_fix = ymd_hms(sensor_start_date_and_time),
    sensor_end_date_and_time_fix = ymd_hms(sensor_end_date_and_time)
  ) %>%
  select(-c(sequence_date, sequence_datetime)) %>%
  rename(
    sequence_date = sequence_date_fix,
    sequence_datetime = sequence_datetime_fix,
    latitude = latitude_fix,
    longitude = longitude_fix
  )
rm(taxa, full_mol, mol_mamms, matched_v2, matched_v3, still_unmatched, final_unmatched)

# Fix search effort -----------------------------------------------------------------------
setwd("~/project/WI_2024/Wildlife Insights Data_2024")

# look at NAs
missing.vals <- sequence[is.na(sequence$sensor_start_date_and_time_fix),]
head(missing.vals[,c("sensor_start_date_and_time_fix", "sensor_start_date_and_time")]) #confirming not messed up in conversion 
unique(missing.vals$sensor_start_date_and_time) #all values missing
unique(missing.vals$site_name) #multiple projects
View(missing.vals) #can't recover effort information -> delete (831 obs.)
sequence <- sequence %>% filter(!is.na(sensor_start_date_and_time_fix))
missing.vals <- sequence[is.na(sequence$sensor_end_date_and_time_fix),] #no more NA values
rm(missing.vals)

# Look for extreme dates in sensor start/end (note that data were downloaded 2024-09-04) 

# Start times -----------------------------------------------------------------------------
range(sequence$sensor_start_date_and_time) #1928-03-05 to 2024-09-01 
sort(unique(year(sequence$sensor_start_date_and_time)))

# Replace sensor start date with first time deployment time 
View(bad.date <- sequence[year(sequence$sensor_start_date_and_time) == 1928,])
View(bad.date <- sequence[year(sequence$sensor_start_date_and_time) == 1999,])
View(bad.date <- sequence[year(sequence$sensor_start_date_and_time) == 2000,])
View(bad.date <- sequence[year(sequence$sensor_start_date_and_time) == 2024 & month(sequence$sensor_start_date_and_time) == 9,])

sequence <- sequence %>%
  mutate(sensor_start_date_and_time = case_when(
    year(sensor_start_date_and_time) == 1928 ~ first_image_deployment_time,
    year(sensor_start_date_and_time) == 1999 ~ first_image_deployment_time,
    year(sensor_start_date_and_time) == 2000 ~ first_image_deployment_time,
    year(sensor_start_date_and_time) == 2024 & month(sensor_start_date_and_time) == 9 ~ first_image_deployment_time,
    TRUE ~ sensor_start_date_and_time
  ))

# As part of above, identified a few sensor end dates can fix with last image deployment time
sequence <- sequence %>%
  mutate(sensor_end_date_and_time = case_when(
    year(sensor_start_date_and_time) == 1928 ~ last_image_deployment_time,
    year(sensor_start_date_and_time) == 2000 ~ last_image_deployment_time,
    year(sensor_start_date_and_time) == 2024 & month(sensor_start_date_and_time) == 9 ~ last_image_deployment_time,
    TRUE ~ sensor_end_date_and_time
  ))

# Cannot fix; delete 
View(bad.date <- sequence[year(sequence$sensor_start_date_and_time) == 1963,])
sequence[sequence$deployment_name == "PC_22_d46710",] #no other values in deployment to pull from; delete (4 observations) 
sequence <- sequence[!year(seq$sensor_start_date_and_time) == 1963,]

# End times -------------------------------------------------------------------------------
range(sequence$sensor_end_date_and_time) #1928-03-05 to 2024-09-01 
sort(unique(year(sequence$sensor_end_date_and_time)))

# Replace sensor end date with last time deployment time 
View(bad.date <- sequence[year(sequence$sensor_end_date_and_time) == 2000,])
View(bad.date <- sequence[year(sequence$sensor_end_date_and_time) == 2106,])
View(bad.date <- sequence[year(sequence$sensor_end_date_and_time) == 2028,])
View(bad.date <- sequence[year(sequence$sensor_end_date_and_time) == 2026,])

years_to_fix <- c(2000, 2106, 2028, 2026)
for (yr in years_to_fix) {
  idx <- year(sequence$sensor_end_date_and_time) == yr
  sequence$sensor_end_date_and_time[idx] <- sequence$last_image_deployment_time[idx]
}

# Examine 2025 records 
View(bad.date <- sequence[year(sequence$sensor_end_date_and_time) == 2025,])
unique(bad.date$site_name)
View(bad.date[bad.date$site_name == "Wasatch Wildlife Watch",]) 
View(bad.date[bad.date$site_name == "Jawajawa Jili",]) 
View(bad.date[bad.date$site_name == "Malleefowl Mound Monitoring in the Upper Limestone Coast",]) 
View(bad.date[bad.date$site_name == "Wildlife Utilization and Movements Relative to Culvert Location and Characteristics in Metro Atlanta",])
View(bad.date[bad.date$site_name == "SGCN Small Mammal Surveys",]) 

# 2025: Sites to delete (cannot fix reliably)
sites_to_delete <- c("Wasatch Wildlife Watch", "Malleefowl Mound Monitoring in the Upper Limestone Coast")

# 2025: Sites to fix by using last_image_deployment_time
sites_to_fix <- c("Jawajawa Jili", "Wildlife Utilization and Movements Relative to Culvert Location and Characteristics in Metro Atlanta",  "SGCN Small Mammal Surveys")

# Delete unfixable sites
sequence <- sequence[!(year(sequence$sensor_end_date_and_time) == 2025 & sequence$site_name %in% sites_to_delete), ]

# Fix remaining sites
fix_idx <- (year(sequence$sensor_end_date_and_time) == 2025) & (sequence$site_name %in% sites_to_fix)
sequence$sensor_end_date_and_time[fix_idx] <- sequence$last_image_deployment_time[fix_idx]

# Remove entries with sensor_end_date_and_time in 2035 (wide range of dates, don't really trust )
sequence <- sequence[year(sequence$sensor_end_date_and_time) != 2035, ]

# Capture dates that don't fall between sensor start/end ----------------------------------

bad.date <- sequence[sequence$year > year(sequence$sensor_end_date_and_time) | sequence$year < year(sequence$sensor_start_date_and_time),]
View(bad.date[,c("year", "sensor_start_date_and_time", "sensor_end_date_and_time")])
bad.sites <- (unique(bad.date$site_name))
View(bad.date[bad.date$site_name == bad.sites[2],][c("sequence_start_time", "sequence_end_time", "sensor_start_date_and_time", "sensor_end_date_and_time", "first_image_deployment_time", "last_image_deployment_time")])
# -> some of these could be saved, but would require a very large amount of manual review; given that: 
nrow(bad.date)/nrow(seq)*100
# this represents ~1% of the entire dataset, delete for now 
sequence <- sequence[!(sequence$year > year(sequence$sensor_end_date_and_time) | sequence$year < year(sequence$sensor_start_date_and_time)),]

# Check for any cases where end date is before start date
bad.date <- sequence[year(sequence$sensor_end_time_and_time) < year(sequence$sensor_start_date_and_time),] #0 records 

# Clean and save data ---------------------------------------------------------------------
head(sequence); names(sequence)
sequence <- sequence %>% select(-c(sensor_start_date_and_time_fix, sensor_end_date_and_time_fix))

write.csv(sequence, "sequences_updated_20240710.csv", row.names=F)

######################################################################################
##### IMAGES #########################################################################
######################################################################################

setwd("~/project/WI_2024/Wildlife Insights Data_2024")
rm(list=ls()); gc()

# Load libraries -----------------------------------------------------------------------

library(tidyverse)
library(stringr)
library(lubridate)
library(data.table)
library(tibble)
library(CoordinateCleaner)
library(dplyr)
library(ggmap)
library(arrow)

# Load  and filter data ----------------------------------------------------------------

# Private project IDs to exclude 
rm_project_id <- c(2007556, 2007371, 2006485, 2006885, 2006031, 2003854, 2004980, 2006913)

# Project status 
status <- read.csv("20240904_project_status_WI.csv")

# Image data 
image <- read.delim("20240904_science_vw_all_ids_with_time_lag_20240904.txt") 
nrow(image) #59911862

# Remove private projects
image <- image %>% filter(!project_id %in% rm_project_id)
nrow(image) #59872157
head(image) 

# Fix shifted columns --------------------------------------------------------------------

# Review 
taxonomies <- unique(image$taxonomy_subtype)
shifted_seqs <- taxonomies[!taxonomies %in% c("wild-animal", "human", "admin", "domestic-animal", "object", "physical", "wild animal", "")]
unique(image[image$taxonomy_subtype %in% shifted_seqs,]$site_name) #3 sites   

# Correct single column shift: all original columns shifted by one; from "photo_date" 
View(image[image$taxonomy_subtype %in% shifted_seqs & image$site_name == "SIMDeer BC Project",]) 
sub_shift1 <- image %>% filter(taxonomy_subtype %in% shifted_seqs, site_name == "SIMDeer BC Project")
sub_shift1[, 16:51] <- sub_shift1[, 17:52]
sub_shift1$ageinmin <- ""

# Correct two column shift: all original columns shifted by two; from "sub_project" 
View(image[image$taxonomy_subtype %in% shifted_seqs & image$site_name == "Monitoramento de Biodiversidade  de SP - PE Morro do Diabo",])
View(image[image$taxonomy_subtype %in% shifted_seqs & image$site_name == "Cámaras Trampa_PNR_Cerro Pàramo de Miraflores",])
sub_shift2 <- image %>%
  filter(taxonomy_subtype %in% shifted_seqs, 
         site_name %in% c("Monitoramento de Biodiversidade  de SP - PE Morro do Diabo", "Cámaras Trampa_PNR_Cerro Pàramo de Miraflores"))
sub_shift2[, 10:51] <- sub_shift2[, 11:52]
sub_shift2[, 16:51] <- sub_shift2[, 17:52]
sub_shift2$ageinmin <- ""
sub_shift2$timelag <- ""

# Rebuild image dataset 
image <- image[!image$taxonomy_subtype %in% shifted_seqs, ]
image <- bind_rows(image, sub_shift1, sub_shift2)
nrow(image); unique(image$taxonomy_subtype)
rm(sub_shift1); rm(sub_shift2)

# Examine "" (empty) taxonomy columns 
empty_tax <- image[image$taxonomy_subtype == "",]
View(empty_tax) #oh boy, lots going on 
unique(empty_tax$sensor_start_date_and_time) #will have to delete these anyway, as no search effort 
image <- image %>% filter(taxonomy_subtype != "")
rm(image <- image %>% filter(taxonomy_subtype != ""))
unique(image$taxonomy_subtype)

# Format columns -------------------------------------------------------------------------
image <- image %>%
  mutate(
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude),
    photo_date = as.Date(photo_date, "%Y-%m-%d"),
    photo_datetime = as.POSIXct(photo_datetime, "%Y-%m-%d %H:%M:%S"))
nrow(image) #59693229

# Select taxonomy of interest ------------------------------------------------------------
unique(image$class)  

# Quick check 
check <- image[image$class == "",]
unique(check$common_name_english)
unique(check[check$common_name_english == "Animal",]$taxonomy_subtype) #can ignore 
rm(check)

# Subset to mammals and birds 
image <- image %>% filter(class %in% c("Mammalia", "Aves")

# Remove humans and other non-wild animals
unique(image$taxonomy_subtype)
image <- image %>% filter(taxonomy_subtype %in% c("wild-animal", "wild animal")
image[image$taxonomy_subtype == "wild animal",]$taxonomy_subtype <- "wild-animal"
nrow(image) #42010019

# Extract and process project metadata ---------------------------------------------------

project_data <- image %>%
  select(project_id, project_metadata) %>%
  mutate(project_metadata = str_replace_all(project_metadata, "[{}]", "")) %>%
  distinct()

# Split metadata into columns 
metadata_split <- str_split_fixed(project_data$project_metadata, ",", n = Inf)
metadata_df <- as.data.frame(metadata_split)
project_data <- bind_cols(project_data["project_id"], metadata_df)

# Refine to individual projects 
project_data <- distinct(project_data)
nrow(project_data) #1798
head(project_data)

# Remove problematic rows temporarily: issues caused by some answers containing commas while columns are also delimited by commas
to_fix <- project_data %>% filter(V34 != "") #2 rows 
to_fix <- project_data %>% filter(V34 != "")

# Set up metadata dataframe 
metadata_cols <- c(
  "project_id", "country_code", "project_admin", "project_species", "project_bait_use",
  "project_admin_email", "project_blank_images", "project_sensor_layout", "project_sensor_method", 
  "project_sensor_cluser", "project_stratification", "project_individual_animals"
)
project_metadata <- as.data.frame(matrix(ncol = length(metadata_cols), nrow = 0))
colnames(project_metadata) <- metadata_cols

# Fix known text issues in metadata (trailing backslashes) 
project_data$V17[102] <- "Negev Highlands and Hyper Arid South (Arava Valley)"
project_data$V15[136] <- "Control (in treatment area in restoration treatment)"
project_data$V16[136] <- ""
project_data$V12[155] <- "project_stratification_type: 3 study areas differing in levels of disturbance"
project_data$V13[155] <- project_data$V14[155] <- project_data$V15[155] <- project_data$V16[155] <- project_data$V17[155] <- project_data$V18[155] <- project_data$V19[155] <- project_data$V20[155] <- project_data$V21[155] <- project_data$V22[155] <- project_data$V23[155] <- project_data$V24[155] <- ""
project_data$V13[428]  <- "project_sensor_layout_targeted_type: Feeding beds, scat, tracks, vegetation damanage, suitable habitat"
project_data$V14[428] <- project_data$V15[428] <- project_data$V16[428] <- project_data$V17[428] <- project_data$V18[428] <- project_data$V19[428] <- project_data$V20[428] <- ""
project_data$V13[649]  <- "project_sensor_layout_targeted_type: Feeding beds, scat, tracks, vegetation damanage, suitable habitat"
project_data$V14[649] <- project_data$V15[649] <- project_data$V16[649] <- project_data$V17[649] <- project_data$V18[649] <- project_data$V19[649] <- project_data$V20[649] <- ""
project_data$V13[1057]  <- "project_stratification_type: Sensors are primarily subdivided by farm crop composition half growing edible crops and half growing non-palatable crops farms"
project_data$V14[1057] <- project_data$V15[1057] <- project_data$V16[1057] <- project_data$V17[1057] <- project_data$V18[1057] <- project_data$V19[1057] <- project_data$V20[1057] <- project_data$V21[1057] <- project_data$V22[1057] <- project_data$V23[1057] <- project_data$V24[1057] <- project_data$V25[1057] <- project_data$V26[1057] <-""

# Populate metadata dataframe
for(i in 1:nrow(project_data)){
  sub <- project_data[i,]
  sub <- sub[nzchar(sub)] #removes surrounding ""
  project_metadata[i,1] <- as.character(sub[1,1])
  for(j in 2:length(sub)){
    x <- trimws(strsplit(as.character(sub[j]), "[:]")[[1]][1])
    y <- trimws(strsplit(as.character(sub[j]), "[:]")[[1]][2])
    cols <- grep(x, names(project_metadata))
    project_metadata[i,cols] <- y
  }
}
head(project_metadata)

# Add manually corrected rows 
to_fix_df <- data.frame(
  project_id = c("2006149", "2006834"),
  country_code = c("IDN", "IDN"),
  project_admin = c("Sonja Heiliger", "Valentin Michel"),
  project_species = c("Multiple", "Multiple"),
  project_bait_use = c("No", "No"),
  project_admin_email = c("sonja.heiliger@stud.uni-goettingen.de", "valentin.joseph.michel@gmail.com"),
  project_blank_images = c("No", "No"),
  project_sensor_layout = c("Randomized", "Systematic"),
  project_sensor_method = c("Sensor detection", "Sensor detection"),
  project_sensor_cluser = c("No", "No"),
  project_stratification = c("Yes", "Yes"),
  project_individual_animals = c("No", "No"),
  stringsAsFactors = FALSE
)
project_metadata <- bind_rows(project_metadata, to_fix_df)

# Join with status table
project_metadata <- plyr::join(project_metadata, status, by="project_id")
rm(proj_id); rm(project_data); rm(sub); rm(to_fix); rm(to_fix_df)

# Clean and combine image data -----------------------------------------------------------
head(image); names(image)

image <- image %>%
  select(-project_metadata) %>%
  mutate(
    latitude_fix = as.numeric(latitude),
    longitude_fix = as.numeric(longitude),
    photo_date_fix = as.Date(photo_date, "%Y-%m-%d"),
    photo_datetime_fix = as.POSIXct(photo_datetime, "%Y-%m-%d %H:%M:%S")
  )

# Combine dataframes 
image <- plyr::join(image, project_metadata, by="project_id")
head(image)

# Examine and fix taxonomy ---------------------------------------------------------------

# Examine data with no species ID 
sum(is.na(image$sp_binomial)) #0

# examine data with blank species ID 
nrow(image[image$sp_binomial == "",]) #7702723
head(image[image$sp_binomial == "",]); tail(image[image$sp_binomial == "",])
unique(image[image$sp_binomial == "",]$common_name_english) #most not id'ed to genus
unique(image[image$common_name_english == "Mammal",]$order) #no other data 
image <- image[!image$sp_binomial == "",] #remove 
nrow(image) #34307296

# Remove "test" or "demo" projects -------------------------------------------------------

image <- image %>%
  mutate(site_name_lower = tolower(site_name),
         site_name_testordemo = case_when(
           grepl("test", site_name_lower) ~ "test",
           grepl("demo", site_name_lower) ~ "demo",
           TRUE ~ "fine"))
testordemo <- image %>% filter(site_name_testordemo %in% c("test", "demo"))
unique(testordemo$site_name)

# How many entries per project? Assume that demos are small 
(demo_freq <- as.data.frame(table(testordemo$site_name)))
demo_freq[demo_freq$Freq > 500,]

# Manually examine these further (>500 images uploaded )
head(image[image$site_name == "DCTestGoldSet",]) #fine
head(image[image$site_name == "Don Test of System",]) #remove (same as above?)
head(image[image$site_name == "Fototrampeo Piedemonte Casanare Convenio Ecopetrol ",]) #fine
head(image[image$site_name == "Fototrampeo_TEAM_Piedemonte_Cauca",]) #fine
head(image[image$site_name == "I-5 Test Camera 74 NW",]) #fine
head(image[image$site_name == "Mads test Central NSW type image",]) #fine
head(image[image$site_name == "NAMDONG_Test",]) #fine
head(image[image$site_name == "Proyecto Vida Silvestre: Piedemonte andino-amazónico",]) #fine
head(image[image$site_name == "Sierra Nevada Carnivore Monitoring Program - TEST",]) #fine
head(image[image$site_name == "Southern Forests test project",]) #fine
head(image[image$site_name == "TEST",]) #hm, remove 
head(image[image$site_name == "Velebit Mountains Wildlife Test Project",]) #fine
head(image[image$site_name == "Wildlife Camera Project - Pilot Study 2022 - Test 3 (Image)",]) #fine

keep_sites <- c("DCTestGoldSet", "Fototrampeo Piedemonte Casanare Convenio Ecopetrol ", "Fototrampeo_TEAM_Piedemonte_Cauca", "I-5 Test Camera 74 NW", "Mads test Central NSW type image", "NAMDONG_Test", "Proyecto Vida Silvestre: Piedemonte andino-amazónico", "Sierra Nevada Carnivore Monitoring Program - TEST", "Southern Forests test project", "Velebit Mountains Wildlife Test Project", "Wildlife Camera Project - Pilot Study 2022 - Test 3 (Image)")

# Remove test and demo projects 
image <- image %>%
  filter(!(site_name_testordemo %in% c("test", "demo") & !site_name %in% keep_sites)) %>%
  select(-site_name_lower, -site_name_testordemo)
rm(testordemo)
nrow(image) #34264245

# Spatial fixes --------------------------------------------------------------------------

# Examine longitude 
range(image$longitude_fix) #should be -180 to 180; some NAs
na_imgs <- image[is.na(image$longitude_fix),]
View(na_imgs) #no data - have to delete
image <- image %>% filter(!is.na(longitude_fix))
range(image$longitude_fix) #should be -180 to 180; now okay 
rm(na_imgs)

# Examine latitude 
range(image$latitude_fix) #should be -90 to 90; some wonky coords! 

wonky_coord <- image[image$latitude_fix < -90,]
View(wonky_coord); unique(wonky_coord$site_name) #one site; these are flipped 
wonky_coord_lat <- wonky_coord$longitude_fix
wonky_coord_long <- wonky_coord$longitude_fix
wonky_coord$longitude_fix <- wonky_coord_long
wonky_coord$latitude_fix <- wonky_coord_lat
range(wonky_coord$latitude_fix) #did this fix? 
image <- image[!image$latitude_fix < -90,]
image <- rbind(image, wonky_coord)

range(image$latitude_fix) #should be -90 to 90; some wonky coords! 

wonky_coord <- image[image$latitude_fix > 90,]
View(wonky_coord) #shifted/duplicated columns 
wonky_coord_lat <- wonky_coord$longitude 
wonky_coord_long <- wonky_coord$deployment_location_id
wonky_coord$longitude_fix <- wonky_coord_long
wonky_coord$latitude_fix <- wonky_coord_lat
range(wonky_coord$latitude_fix) #did this fix? 
image <- image[!image$latitude_fix > 90,]
image <- rbind(image, wonky_coord)
range(image$latitude_fix) #should be -90 to 90; now okay
rm(wonky_coord)

# Examine 0,0 coordinates
nrow(sub <- image[image$longitude_fix == 0 & image$latitude_fix == 0,]) #962
unique(sub$organization_name) #4 orgs 
View(sub[sub$organization_name == "University of Nevada, Las Vegas (UNLV)",]) #no long/lat info 
View(sub[sub$organization_name == "Wildlife Conservation Society Uganda",]) #no long/lat info 
View(sub[sub$organization_name == "Hobart Airport",]) #no long/lat info anywhere else 
View(sub[sub$organization_name == "Western EcoSystems Technology, Inc",]) #no long/lat info 
image <- image %>% filter(!(longitude_fix == 0 & latitude_fix == 0))
nrow(image) #34263032

# Check for sites in water ---------------------------------------------------------------

image$longitude_fix <- as.numeric(image$longitude_fix)
image$over_water <- CoordinateCleaner::cc_sea(image, lon = "longitude_fix", lat = "latitude_fix", value = "flagged")

# Identify flagged "water" points
water_pts <- image %>% filter(over_water == "FALSE") #872769 observations

# Remove coastal/island projects 
unique(water_pts$site_name) #which appear to be near water? 
coastal <- c("Lehua Island Invasive Rodent Survey", "Mona Island Restoration Project", "Floreana Island Restoration Project", "Palau Islands Restoration Project", "Ulithi Atoll Restoration Project", "Juan Fernandez Islands Restoration Project", "Central Coast Deer Abundance 2017-18 (CCDA 2017-18)", "Kangaroo Island Dunnart Project", "South Walney Gull Colony Monitoring", "Catalina Island Shrew ", "Bowen Island", "ZSL Philippines IWTCF", "Exotic Herbivores in Isla de los Estados, Tierra del Fuego, Argentina", "Caracterización de mamíferos medianos y grandes en la zona marino-costera del Litoral del San Juan-Chocó, Colombia.", "Kangaroo Island Dunnart Data", "American Oystercatcher Camera Trap Study ", "Protecting Mayala island biodiversity and coastal environments", "Quoll Cameras- Sunshine Coast Hinterland- 2024")  
water_pts <- water_pts %>% filter(!site_name %in% coastal_sites)
unique(water_pts$site_name) #74 sites
rm(coastal)

# Manually review 
head(sub[sub$site_name == "Makira NP Carnivore survey 2011: Farankarina Forest",]) #on the coast
head(sub[sub$site_name == "ENTMRPA Wildlife Monitoring",]) #on coast 
head(sub[sub$site_name == "Quokka recovery in Northcliffe fire zone",]) #on coast 
head(sub[sub$site_name == "Southeast Alaska Deer-Habitat Relationships",]) #on coast 
head(sub[sub$site_name == "Camera Trapping to Monitor Meso-Carnivore Populations at Brookhaven National Laboratory Campus",]) #on coast 
head(sub[sub$site_name == "Bukit Barisan",]) #on coast 
head(sub[sub$site_name == "Marin County Deer Abundance 2015-16 (MCDA 2015-16)",]) #on coast 
head(sub[sub$site_name == "ifv",]) #on coast 
head(sub[sub$site_name == "Ellsworth Creek Preserve Pilot Wildlife Study",]) #on coast 
head(sub[sub$site_name == "Region 5 Bobcat Program",]) #on coast 
head(sub[sub$site_name == "MDG-009 Makira NP Carnivore survey 2011: Farankarina Forest",]) #on coast 
head(sub[sub$site_name == "Development of ML Algorithim for T&T Megafauna Detection Using Camera Traps",]) #on coast 
head(sub[sub$site_name == "Snapshot Seattle 2021 (Seattle Urban Carnivore Project)",]) #on coast   
head(sub[sub$site_name == "NPWS Wildcount datasets",]) #on coast 
head(sub[sub$site_name == "Velebit Mountains",]) #on coast   
head(sub[sub$site_name == "BIOL2105 Old Camera Trapping",]) #on coast 
head(sub[sub$site_name == "The NYC Urban Wildlife Monitoring Transect",]) #on coast 
head(sub[sub$site_name == "Project ECOTONE",]) #on coast 
head(sub[sub$site_name == "Region 3 Bobcat Program",]) #on coast 
head(sub[sub$site_name == "BIOL2015 Field Trip Camera Trapping",]) #on coast 
head(sub[sub$site_name == "The Green-Wood Cemetery Wildlife Monitoring Project",]) #on coast 
head(sub[sub$site_name == "Australian Wet Tropics Camera Trap Surveys",]) #on coast 
head(sub[sub$site_name == "TIDE Private Protected Lands",]) #on coast 
head(sub[sub$site_name == "The Science Talent Project",]) #on coast 
head(sub[sub$site_name == "BHVPF",]) #on coast 
head(sub[sub$site_name == "Evaluation de l'impact des actions de régulation des prédateurs exotiques envahissants sur des sites d'interet ecologiques majeurs",]) #on coast 
head(sub[sub$site_name == "Makua Valley Pig Eradication",]) #on coast 
head(sub[sub$site_name == "Rodent and Feral Fowl Exclosures",]) #on coast 
head(sub[sub$site_name == "Development of devil facial tumour vaccine distribution and efficacy monitoring systems",]) #on coast 
head(sub[sub$site_name == "Rio San Juan",]) #on coast 
head(sub[sub$site_name == "Ranch House",]) #on coast 
head(sub[sub$site_name == "Scorpion Fire Cameras",]) #on coast 
head(sub[sub$site_name == "OCP-2022 Camera Grid",]) #on coast 
head(sub[sub$site_name == "Roots & Shoots Tanzania",]) #on coast 
head(sub[sub$site_name == "SSN Mammals",]) #on coast 
head(sub[sub$site_name == "Ban QLRPH Bac Hai Van",]) #on coast 
head(sub[sub$site_name == "Olympic Cougar Project 2023 Camera Grid",]) #on coast 
head(sub[sub$site_name == "Eden State Forest",]) #on coast 
head(sub[sub$site_name == "Elwha Lakebeds Year 3",]) #on coast 
head(sub[sub$site_name == "JCalzada_Doñana",]) #on coast  
head(sub[sub$site_name == "Eastern Quoll Project",]) #on coast 
head(sub[sub$site_name == "Bardi Jawi Biodiversity ",]) #on coast 
head(sub[sub$site_name == "Exclosure Monitoring",]) #close enough
head(sub[sub$site_name == "North Fork - Phase 2",]) #on coast 
head(sub[sub$site_name == "EG Rapid Assessment Program",]) #on coast 
head(sub[sub$site_name == "Targeted northern quoll surveys",]) #on coast 

#latitude should be negative
head(sub[sub$site_name == "Mount Glorious Ecosystem",])
head(sub[sub$site_name == "Wollombi Valley Landcare Hollow Homes 2023",])
head(sub[sub$site_name == "Mads test Central NSW type image",]) 
head(sub[sub$site_name == "Harami WF",])  
head(sub[sub$site_name == "Greater Glider Nest Box",])  
head(sub[sub$site_name == "Minyumai Ngugum Project for Banjalang Country",])
to_fix_lat <- c("Mads test Central NSW type image", "Harami WF", "Greater Glider Nest Box", "Minyumai Ngugum Project for Banjalang Country", "Wollombi Valley Landcare Hollow Homes 2023", "Mount Glorious Ecosystem") 

#long should be negative 
head(sub[sub$site_name == "Makaha",])
head(sub[sub$site_name == "FIBTEX - Reserva Natural El Amparo",])
head(sub[sub$site_name == "Hillside",]) 
head(sub[sub$site_name == "Wildlife Monitoring Acosta",])
head(sub[sub$site_name == "Monitoreo de mamíferos en la fundación Cerros de Bogotá Umbral Cultural Horizontes",])
head(sub[sub$site_name == "Morro Dunes camera trapping",])
to_fix_long <- c("Hillside", "Wildlife Monitoring Acosta", "Monitoreo de mamíferos en la fundación Cerros de Bogotá Umbral Cultural Horizontes", "FIBTEX - Reserva Natural El Amparo", "Makaha", "Morro Dunes camera trapping")

#both lat and long should be negative 
head(sub[sub$site_name == "MEIN REGENWALD",])
head(sub[sub$site_name == "CT - Puno",])
to_fix_latlong <- c("MEIN REGENWALD", "CT - Puno")

#latitude needs shift 1 decimal place 
head(sub[sub$site_name == "wildlife monitoring using camera traps ",])
shift_lat <- "wildlife monitoring using camera traps "

#both long and lat off by 2 decimal places
head(sub[sub$site_name == "Native Species Assessment and Monitoring in Miami-Dade County",])
shift_latlong <- "Native Species Assessment and Monitoring in Miami-Dade County"

#flipped lat and long
head(sub[sub$site_name == "Luambe National Park Species Inventory",])  
to_fix_flipped <- "Luambe National Park Species Inventory"

#to delete 
head(sub[sub$site_name == "Count optional",]) #looks like a demo - delete (1 obs) 
head(sub[sub$site_name == "TZA-001 Inventory of medium-to-large, terrestrial forest mammals and birds in the Tanzanian Eastern Arc Mountains",]) #lat should be negated; long is off by a few degrees for purported site... delete for now
head(sub[sub$site_name == "Spotted Skunks - Image Project Type",]) #coords wrong and imprecise; delete for now 
head(sub[sub$site_name == "Expedición Oso Palmero",]) #lat and long same, both wrong - delete 
head(sub[sub$site_name == "gouldian finch ",]) #coords kind of right, but off enough - delete 
head(sub[sub$site_name == "2002_KSWS_CameraTrap_Multi-speciesOccurrence",]) #coords off - delete 
head(sub[sub$site_name == "Camera Traps2",]) #off, not flipped, not negated - delete 
head(sub[sub$site_name == "First Collection SCMA 29-30.3.2024",]) #coords too imprecise 
head(sub[sub$site_name == "HBA Fauna Camera",]) #coords imprecise and wrong 
head(sub[sub$site_name == "Wild pig",]) #coords wrong 
head(sub[sub$site_name == "memoire beno",]) #2 obs + no date-time - delete 
to_delete <- c("Count optional", "TZA-001 Inventory of medium-to-large, terrestrial forest mammals and birds in the Tanzanian Eastern Arc Mountains", "Spotted Skunks - Image Project Type", "Expedición Oso Palmero", "gouldian finch ", "2002_KSWS_CameraTrap_Multi-speciesOccurrence", "Camera Traps2", "First Collection SCMA 29-30.3.2024", "HBA Fauna Camera", "Wild pig", "memoire beno") 

# Delete unsalvagable sites 
image <- image %>% filter(!(site_name %in% to_delete & over_water == "FALSE"))
rm(to_delete)

# Fix latitudes that need to be negated 
image <- image %>%
  mutate(latitude_fix = ifelse(site_name %in% to_fix_lat & over_water == "FALSE" & latitude_fix > 0, -latitude_fix, latitude_fix))
rm(to_fix_lat)

# Fix longitudes that need to be negated 
image <- image %>%
  mutate(longitude_fix = ifelse(site_name %in% to_fix_long & over_water == "FALSE" & longitude_fix > 0, -longitude_fix, longitude_fix))
rm(to_fix_long)

# Fix where latitude and longitude need to be negated 
image <- image %>%
  mutate(latitude_fix = ifelse(site_name %in% to_fix_latlong & over_water == "FALSE" & latitude_fix > 0, -latitude_fix, latitude_fix),
         longitude_fix = ifelse(site_name %in% to_fix_latlong & over_water == "FALSE" & longitude_fix > 0, -longitude_fix, longitude_fix))
rm(to_fix_latlong)

# Shift latitude by factor 10 
image <- image %>%
  mutate(latitude_fix = ifelse(site_name %in% shift_lat & over_water == "FALSE", latitude_fix * 10, latitude_fix))
rm(shift_lat)

# Shift both lat and long by factor 100
image <- image %>%
  mutate(latitude_fix = ifelse(site_name %in% shift_latlong & over_water == "FALSE", latitude_fix * 100, latitude_fix),
         longitude_fix = ifelse(site_name %in% shift_latlong & over_water == "FALSE", longitude_fix * 100, longitude_fix))
rm(shift_latlong)

# Flip latitude and longitude 
image <- image %>%
  mutate(
    latitude_fix = ifelse(site_name %in% to_fix_flipped & over_water == "FALSE", longitude_fix, latitude_fix),
    longitude_fix = ifelse(site_name %in% to_fix_flipped & over_water == "FALSE", latitude_fix, longitude_fix))
rm(to_fix_flipped)

# Temporal data --------------------------------------------------------------------------

# Examine NA dates 
sum(is.na(image$photo_date_fix)) #316177
sub <- image[is.na(image$photo_date_fix),]
length(unique(sub$site_name)) #72
View(sub) #no other date info available 
image <- image %>% filter(!is.na(photo_date_fix))
sum(is.na(image$photo_datetime_fix)) #0

# Examine problematic years 
range(image$photo_date) #1900-01-01 to 2293-12-22
sort(unique(image$year))

View(image[image$year == 1900,]) #not enough information to correct; 14 sites 
View(image[image$year == 1902,]) #not enough information to correct; 1 obs 
View(image[image$year == 1936,]) #not enough information to correct; 1 obs 
View(image[image$year == 1961,]) #not enough information to correct; note camera damage
View(image[image$year == 1980,]) #not enough information to correct; 11 obs 
image <- image[!image$year %in% c(1900, 1902, 1936, 1961, 1980),]

View(image[image$year == 1970,]) #not enough information to correct; 1 obs 
unique(image[image$year == 1970,]$photo_time) #00:00:00 entries unrecoverable 
image <- image[!(image$year == 1970 & image$photo_time == "00:00:00"),]
unique(image[image$year == 1970,]$month) #1, 2 - likely started at 1970-01-01... 
View(image[image$year == 1970,]) #these also unrecoverable 
image <- image[!image$year == 1970,]

View(image[image$year == 1999,]) #these appear fine 

View(image[image$year == 2293,])
unique(image[image$year == 2293,]$site_name) #3 projects 
View(image[image$year == 2293 & image$site_name == "Envigado 2023",]) #months don't fall between sensor start/end dates 
View(image[image$year == 2293 & image$site_name == "BACLIP",]) #months don't fall between sensor start/end dates 
View(image[image$year == 2293 & image$site_name == "Monitoreo de fauna en 21 comunidades nativas ",]) #months don't fall between sensor start/end dates 
image <- image[!image$year == 2293,]

View(image[image$year == 2242,]) #only one of dates falls between month-day of sensor start/end dates, so not convinced year is just off
image <- image[!image$year == 2242,]

View(image[image$year == 2222,]) #year meant to be 2022 
sub <- image[image$year == 2222,] %>% 
  mutate(df_time = ymd_hms(df_time)) %>% 
  mutate(first_image_deployment_time = ymd_hms(first_image_deployment_time)) %>% 
  mutate(last_image_deployment_time = ymd_hms(last_image_deployment_time)) %>% 
  mutate(photo_date_fix = ymd(photo_date_fix)) %>% 
  mutate(photo_datetime_fix = ymd_hms(photo_datetime_fix))
sub$year <- sub$year - 200
sub$df_time <- sub$df_time - years(200)
sub$first_image_deployment_time <- sub$first_image_deployment_time - years(200)
sub$last_image_deployment_time <- sub$last_image_deployment_time - years(200)
sub$photo_date_fix <- sub$photo_date_fix - years(200)
sub$photo_datetime_fix <- sub$photo_datetime_fix - years(200)
head(sub)
sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")] <- lapply(sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")], as.character)
image <- image[!image$year == 2222,]
image <- rbind(image, sub)
rm(sub)

View(image[image$year == 2137,]) #116 years off 
sub <- image[image$year == 2137,] %>% 
  mutate(df_time = ymd_hms(df_time)) %>% 
  mutate(first_image_deployment_time = ymd_hms(first_image_deployment_time)) %>% 
  mutate(last_image_deployment_time = ymd_hms(last_image_deployment_time)) %>% 
  mutate(photo_date_fix = ymd(photo_date_fix)) %>% 
  mutate(photo_datetime_fix = ymd_hms(photo_datetime_fix))
sub$year <- sub$year - 116
sub$df_time <- sub$df_time - years(116)
sub$first_image_deployment_time <- sub$first_image_deployment_time - years(116)
sub$last_image_deployment_time <- sub$last_image_deployment_time - years(116)
sub$photo_date_fix <- sub$photo_date_fix - years(116)
sub$photo_datetime_fix <- sub$photo_datetime_fix - years(116)
head(sub)
sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")] <- lapply(sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")], as.character)
image <- image[!image$year == 2137,]
image <- rbind(image, sub)
rm(sub)

View(image[image$year == 2099,]) #76 years off 
sub <- image[image$year == 2099,] %>% 
  mutate(df_time = ymd_hms(df_time)) %>% 
  mutate(first_image_deployment_time = ymd_hms(first_image_deployment_time)) %>% 
  mutate(last_image_deployment_time = ymd_hms(last_image_deployment_time)) %>% 
  mutate(photo_date_fix = ymd(photo_date_fix)) %>% 
  mutate(photo_datetime_fix = ymd_hms(photo_datetime_fix))
sub$year <- sub$year - 76
sub$df_time <- sub$df_time - years(76)
sub$first_image_deployment_time <- sub$first_image_deployment_time - years(76)
sub$last_image_deployment_time <- sub$last_image_deployment_time - years(76)
sub$photo_date_fix <- sub$photo_date_fix - years(76)
sub$photo_datetime_fix <- sub$photo_datetime_fix - years(76)
head(sub)
sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")] <- lapply(sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")], as.character)
image <- image[!image$year == 2099,]
image <- rbind(image, sub)
rm(sub)

View(image[image$year == 2101,]) #missing search effort data 
unique(image[image$year == 2101,]$site_name) #one site 
image <- image[!image$year == 2101,]

View(image[image$year == 2208,]) #months don't fall between sensor start/end dates; one site 
View(image[image$year == 2200,]) #months don't fall between sensor start/end dates; one site 
View(image[image$year == 2190,]) #months don't fall between sensor start/end dates; one site 
View(image[image$year == 2138,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2124,]) #don't think can fix - months off (?)
View(image[image$year == 2073,]) #date predates sensor start date; one site 
View(image[image$year == 2072,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2045,]) #don't think can fix - months off (?)
View(image[image$year == 2043,]) #lag between first and last image deployment time 
View(image[image$year == 2033,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2032,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2031,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2030,]) #months don't fall between sensor start/end dates; two sites
View(image[image$year == 2029,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2028,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2026,]) #months don't fall between sensor start/end dates; one site
View(image[image$year == 2025,]) #months don't fall between sensor start/end dates; nine sites
image <- image[!image$year %in% c(2208, 2200, 2190, 2138, 2124, 2073, 2072, 2045, 2043, 2033, 2032, 2031, 2030, 2029, 2028, 2026, 2025),]

sort(unique(image$year))

sub <- image[image$year == 2024 & image$month > 8,] #can't be greater than september 
unique(sub$site_name)
View(sub[sub$site_name == "Mlati Ochieng",]) #months don't fall between sensor start/end dates
View(sub[sub$site_name == "PN Catimbau",]) #one year off - can fix 
View(sub[sub$site_name == "Moore Park",]) #one year off - can fix 
View(sub[sub$site_name == "PN Serra da Canastra",]) #could be one year off? "fix" for now 
View(sub[sub$site_name == "Biodiversity index",]) #one year off - can fix
View(sub[sub$site_name == "Mitchell Owen",]) #months don't fall between sensor start/end dates
View(sub[sub$site_name == "5_Bac Vu Quang-Huong Son FC-Ngan Pho river WPFMB - Huong Son - Ha Tinh",]) #one year off - can fix 
View(sub[sub$site_name == "CUBS small mammals 2024",]) #months don't fall between sensor start/end dates
View(sub[sub$site_name == "4_Khe Bung_Khe Tang - Pu Mat - Con Cuong - Nghe An",]) #months don't fall between sensor start/end dates

sub <- sub[!sub$site_name %in% c("Mlati Ochieng", "Mitchell Owen", "CUBS small mammals 2024", "4_Khe Bung_Khe Tang - Pu Mat - Con Cuong - Nghe An"),]
sub <- sub %>% 
  mutate(df_time = ymd_hms(df_time)) %>% 
  mutate(first_image_deployment_time = ymd_hms(first_image_deployment_time)) %>% 
  mutate(last_image_deployment_time = ymd_hms(last_image_deployment_time)) %>% 
  mutate(photo_date_fix = ymd(photo_date_fix)) %>% 
  mutate(photo_datetime_fix = ymd_hms(photo_datetime_fix))
sub$year <- sub$year - 1
sub$df_time <- sub$df_time - years(1)
sub$first_image_deployment_time <- sub$first_image_deployment_time - years(1)
sub$last_image_deployment_time <- sub$last_image_deployment_time - years(1)
sub$photo_date_fix <- sub$photo_date_fix - years(1)
sub$photo_datetime_fix <- sub$photo_datetime_fix - years(1)
head(sub)
sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")] <- lapply(sub[, c("df_time", "first_image_deployment_time", "last_image_deployment_time", "photo_date_fix", "photo_datetime_fix")], as.character)
image <- image[!(image$year == 2024 & image$month > 8),]
image <- rbind(image, sub)
rm(sub)

sort(unique(image$year))
nrow(image) #33933563

# Examine unusual times 
sum(is.na(image$photo_time)) #0
head(sub <- (sequence[sequence$sequence_time == "00:00:00",])); nrow(sub) #201
table(sub$site_name) #nothing looks unreasonable 

# Other checks ---------------------------------------------------------------------------
sum(is.na(image$unique_id)) #0
sort(unique(image$site_name)) #nothing looks too suspicious 

sort(unique(image$organization_name))
head(image[image$organization_name == "My First Organization 1545164058435",]) #data seem okay
head(image[image$organization_name == "My First Organization 1571392225585",]) #data seem okay
head(image[image$organization_name == "My First Organization 1578957414780",]) #data seem okay    
head(image[image$organization_name == "My First Organization 1582273749495",]) #data seem okay    
head(image[image$organization_name == "My First Organization 1588882127163",]) #data seem okay
head(image[image$organization_name == "My First Organization 1593045617195",]) #data seem okay
head(image[image$organization_name == "xxx",]) #data seems okay

head(image[image$organization_name == "A Wildlife Organization",]) #hm, country code is TZA but calld "An Indonesia Project"; ranges in date from 2009 to 2020; a little suspicious 
head(image[image$organization_name == "My First Organization 1576159086430",]) #dates outside search effort 
head(image[image$organization_name == "My First Organization 1586158898487",]) #sensor and image dates don't match (only 1 obs)
head(image[image$organization_name == "My First Organization 1586203210981",]) #sensor and image dates don't match 
head(image[image$organization_name == "My First Organization 1617288502231",]) #sensor and image dates don't match 
head(image[image$organization_name == "bat test data",]) #sensor and image dates don't match 
head(image[image$organization_name == "A new TESTABC",]) #sensor and image dates don't match 

orgs_to_remove <- c("A Wildlife Organization", "My First Organization 1576159086430", 
"My First Organization 1586158898487", "My First Organization 1586203210981", "My First Organization 1617288502231", 
"bat test data", "A new TESTABC")
image <- image %>% filter(!organization_name %in% orgs_to_remove)
nrow(image) #33753380

# Clean up columns -----------------------------------------------------------------------
image <- image %>%
  select(-c(latitude, longitude, over_water, photo_date, photo_datetime)) %>%
  rename(latitude = latitude_fix,
         longitude = longitude_fix,
         photo_date = photo_date_fix,
         photo_datetime = photo_datetime_fix)
head(image)

# Flag spatiotemporal duplicates ---------------------------------------------------------
image$photo_datetime <- as.character(image$photo_datetime)
image$photo_date <- as.character(image$photo_date)
image.dt <- data.table(image)
image.dt$spatiotemp_duplicates <- duplicated(image.dt[, c("sp_binomial", "longitude", "latitude", "photo_datetime"),])
nrow(image.dt[image.dt$spatiotemp_duplicates == TRUE,]) #8167806

# Examine where coming from 
head(sub <- image.dt[image.dt$spatiotemp_duplicates == TRUE,])
length(unique(sub$site_name)) #1225 sites 

image[image$sp_binomial == "Tayassu pecari" & image$photo_datetime == "2011-11-04 15:18:32",] #genuine duplicate? 
image[image$sp_binomial == "Sus scrofa" & image$photo_datetime == "2023-12-24 15:41:51",] #genuine duplicate

image.dt <- image.dt[!image.dt$spatiotemp_duplicates == TRUE,]
image <- as.data.frame(image.dt)
image$spatiotemp_duplicates <- NULL
head(image)

# Taxonomic harmonization ----------------------------------------------------------------

# Load harmonizaiton data 
birds <- read.csv("../WI_Harmonization/Birds_WI_to_MOL_harmonized_20220725.csv")
mamms <- read.csv("../WI_Harmonization/Mammals_WI_to_MOL_harmonized_20220725.csv")
taxa <- rbind(birds, mamms) %>% select(commonNameEnglish, wi_taxon_id, sp_binomial, Accepted_MOL)
rm(mamms, birds)

# Join by WI taxon ID
image <- image %>% left_join(taxa, by = "wi_taxon_id")

# How many remain unmatched 
sum(is.na(image$Accepted_MOL)) #49409

# Try to match remaining using sp_binomial 
unmatched <- image %>%
  filter(is.na(Accepted_MOL)) %>%
  select(1:65, sp_binomial) %>%
  left_join(taxa, by = "sp_binomial")
sum(is.na(unmatched$Accepted_MOL)) #39420 
remaining_sp <- unique(sub$sp_binomial[is.na(sub$Accepted_MOL)])

# Load full MOL harmonization dataset 
full_mol <- read.csv("../WI_Harmonization/WI_harmonized_taxonomy_11_2022.csv")
names(full_mol)[5] <- "sp_binomial"
setdiff(sp_binom, unique(full.mol$Accepted)) #11
setdiff(sp_binom, unique(full.mol$canonical)) #10

# Join with full MOL list 
sub_unmatched <- sub %>%
  filter(is.na(Accepted_MOL)) %>%
  select(1:65, sp_binomial) %>%
  left_join(full_mol, by = "sp_binomial")
nrow(sub_unmatched.1[!is.na(sub_unmatched.1$Accepted),]) #1195

# Create finished subsets
sub_matched_full <- sub_unmatched %>% filter(!is.na(Accepted)) %> mutate(Accepted_MOL = Accepted) %>% select(1:65, Accepted_MOL)
sub_matched_first <- sub %>% filter(!is.na(Accepted_MOL)) %>% select(1:65, Accepted_MOL)

# Keep only initially matched images
image_clean <- image %>% filter(!is.na(Accepted_MOL)) %>% select(1:65, Accepted_MOL)
image <- bind_rows(image_clean, sub_matched_first, sub_matched_full)

# Process final unmatched taxa; load canonical taxonomy 
mamms <- read.csv("../WI_Harmonization/MOL_MammaliaTaxonomy_v2.3_complete_noamb.csv")
birds <- read.csv("../WI_Harmonization/MOL_AvesTaxonomy_v2.3_complete_noamb.csv")
taxa2 <- bind_rows(mamms, birds) %>% filter(valid == TRUE)
names(taxa2)[3] <- "sp_binomial"

setdiff(unique(sub.2$sp_binomial), unique(taxa2$canonical)) #7

# Join with canonical taxonomy 
sub_final_joined <- sub_final_unmatched %>% left_join(taxa2, by = "sp_binomial")
nrow(sub_final_joined.2[is.na(sub_final_joined.2$valid),]) #38061

# Split final matched vs unmatched
sub_final_matched <- sub_final_joined %>%
  filter(!is.na(valid)) %>%
  mutate(Accepted_MOL = paste(genus.1, species.1)) %>%
  select(1:65, Accepted_MOL)

sub_final_remaining <- sub_final_joined %>%
  filter(is.na(valid)) %>%
  mutate(Accepted_MOL = sp_binomial) %>%
  select(1:65, Accepted_MOL)

# Add to image
image <- bind_rows(image, sub_final_matched, sub_final_remaining)

# Cleanup
rm(sub, sub_unmatched, sub_matched_full, sub_matched_first, sub_final_unmatched, sub_final_joined, 
  sub_final_matched, sub_final_remaining, taxa, taxa2, mamms, birds, full_mol)

# Fix search effort ----------------------------------------------------------------------

FROM HERE 

# check issues
sum(is.na(image$sensor_start_date_and_time)) #0
sum(is.na(image$sensor_end_date_and_time)) #0

# format data 
image <- image %>% 
  mutate(photo_date = ymd(photo_date)) %>%
  mutate(sensor_start_date_and_time_fix = ymd_hms(sensor_start_date_and_time)) %>% 
  mutate(sensor_end_date_and_time_fix = ymd_hms(sensor_end_date_and_time))

# look at NAs for start 
missing.vals <- image[is.na(image$sensor_start_date_and_time_fix),]
head(missing.vals[,c("sensor_start_date_and_time_fix", "sensor_start_date_and_time")]) 
unique(missing.vals$sensor_start_date_and_time) #3 kinds 
unique(missing.vals$sensor_end_date_and_time) #3 kinds 
unique(missing.vals$site_name) #5 sites 

View(missing.vals[missing.vals$site_name == "Camaras Trampa_Piamonte_Cauca",]) #can substitute first-img time for sensor-start time 
View(missing.vals[missing.vals$site_name == "Elizabeth Gow",]) #all data missing
View(missing.vals[missing.vals$site_name == "Yasuni",]) #columns shifted - can fix
View(missing.vals[missing.vals$site_name == "Mau Forest Camera Trap Survey",]) #missing all search effort data 
View(missing.vals[missing.vals$site_name == "Deep Learning for Wildlife Species Image Classification",]) #missing all search effort data 

fix.vals.ctpc <- missing.vals[missing.vals$site_name == "Camaras Trampa_Piamonte_Cauca",]
fix.vals.ctpc$sensor_start_date_and_time_fix <- fix.vals.ctpc$first_image_deployment_time
fix.vals.y <- missing.vals[missing.vals$site_name == "Yasuni",]
fix.vals.y <- fix.vals.y |>
  dplyr::mutate(
    camera_status = sensor_start_date_and_time,
    camera_height = sensor_end_date_and_time,
    camera_angle  = first_image_deployment_time,
    bait_type     = last_image_deployment_time,
    sensor_start_date_and_time = feature_type,
    sensor_end_date_and_time   = camera_make,
    first_image_deployment_time = camera_model,
    last_image_deployment_time  = event,
    feature_type = iucn_status, 
    camera_make              = NA,
    camera_model            = NA,
    event = NA,
    iucn_status            = NA
  )
View(fix.vals.y)

image <- image[!is.na(image$sensor_start_date_and_time_fix),]
image <- rbind(image, fix.vals.ctpc)
image <- rbind(image, fix.vals.y)
rm(missing.vals); rm(fix.vals); rm(fix.vals.ctpc); rm(fix.vals.y)
image <- image %>% mutate(sensor_end_date_and_time_fix = ymd_hms(sensor_end_date_and_time))

# look at NA values for end 
nrow(missing.vals <- image[is.na(image$sensor_end_date_and_time_fix),]) #2118
head(missing.vals[,c("sensor_end_date_and_time_fix", "sensor_end_date_and_time")]) 
unique(missing.vals$sensor_end_date_and_time) #1 kind 
unique(missing.vals$site_name) #1 sites 
View(missing.vals) #can substitute last image
missing.vals$sensor_end_date_and_time <- missing.vals$last_image_deployment_time
missing.vals <- missing.vals %>% mutate(sensor_end_date_and_time_fix = ymd_hms(sensor_end_date_and_time))
image <- image[!is.na(image$sensor_end_date_and_time_fix),]
image <- rbind(image, missing.vals)
nrow(image[is.na(image$sensor_end_date_and_time_fix),]) #all fixed
rm(missing.vals)

# look for extreme dates in sensor start/end --- 
# note: data was downloaded 2024-09-04

# start times 
range(image$sensor_start_date_and_time_fix) #NA to NA
View(image[is.na(image$sensor_start_date_and_time_fix),]) 
image[is.na(image$sensor_start_date_and_time_fix),]$sensor_start_date_and_time_fix <- ymd_hms(image[is.na(image$sensor_start_date_and_time_fix),]$sensor_start_date_and_time)
range(image$sensor_start_date_and_time_fix) #1999-06-25 to 2024-07-28 -- all good 

# end times 
range(image$sensor_end_date_and_time_fix) #1999-08-03 to 2099-12-31
sort(unique(year(image$sensor_end_date_and_time_fix)))

View(image[year(image$sensor_end_date_and_time_fix) == 2099,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2032,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2030,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2029,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2027,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2026,]) #use last img deploy 
View(image[year(image$sensor_end_date_and_time_fix) == 2025,]) #use last img deploy 

to.fix <- image[year(image$sensor_end_date_and_time_fix) > 2024,]
to.fix$sensor_end_date_and_time_fix <- to.fix$last_image_deployment_time
image <- image[!(year(image$sensor_end_date_and_time_fix) > 2024),]
image <- rbind(image, to.fix)
rm(to.fix)

range(image$sensor_end_date_and_time_fix) #1999-08-03 to 2034-02-23 
to.fix <- image[year(image$sensor_end_date_and_time_fix) > 2024,]
unique(to.fix$site_name) #these are weird and all over the place; delete
image <- image[!year(image$sensor_end_date_and_time_fix) > 2024,]
range(image$sensor_end_date_and_time_fix) #1999-08-03 to 2024-12-31

to.fix <- image[image$sensor_end_date_and_time_fix > "2024-09-04 00:00:00",]
sites <- unique(to.fix$site_name) #28 sites
View(to.fix[to.fix$site_name == sites[28],]) #run through sites manually 
to.fix <- to.fix[!to.fix$site_name %in% sites[c(4,8,9)],] #delete
to.fix$sensor_end_date_and_time_fix <- to.fix$last_image_deployment_time
to.fix[to.fix$site_name %in% sites[c(10,24)],]$sensor_start_date_and_time_fix <- to.fix[to.fix$site_name %in% sites[c(10,24)],]$first_image_deployment_time #some need start updating
image <- image[!(image$sensor_end_date_and_time_fix > "2024-09-04 00:00:00"),]
image <- rbind(image, to.fix)
rm(to.fix)

# look for capture dates that don't fall between image start/end --- 
bad.date <- image[image$year > year(image$sensor_end_date_and_time_fix) | image$year < year(image$sensor_start_date_and_time_fix),]
View(bad.date[,c("year", "photo_date", "sensor_start_date_and_time_fix", "sensor_end_date_and_time_fix")])
length(unique(bad.date$site_name)) #510 sites 
View(bad.date) #honestly, not really sure how to fix these 
nrow(bad.date)/nrow(image)*100 #<2% of entire dataset; delete for now 
image <- image[!(image$year > year(image$sensor_end_date_and_time_fix) | image$year < year(image$sensor_start_date_and_time_fix)),]

# look for captures where end comes before beginning --- 
nrow(bad.date <- image[year(image$sensor_end_time_and_time_fix) < year(image$sensor_start_date_and_time_fix),]) #0
rm(bad.date)

## save data -- 
names(image)
image <- image %>% 
  select(-c(sensor_start_date_and_time, sensor_end_date_and_time)) %>% 
  rename(sensor_start_date_and_time = sensor_start_date_and_time_fix) %>% 
  rename(sensor_end_date_and_time = sensor_end_date_and_time_fix)

write.csv(image, "images_updated_20240714.csv", row.names=F)
