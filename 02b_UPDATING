#############################################
### Extract static and dynamic covariates ###
#############################################

# This file contains code to create a preannotated version of the covariates for 
# the occupancy models. The types of covariates are: 

# * site-level covariates (static). Format: cells x 1 column per each covariate;
# * primary period-level covariates (dynamic). Format: cells x periods per each covariate. 
#       Some of these covariates (e.g. year) will have the repeated values in more than 
#       one column

# Run 1x

# Note: this extracts values species present in all_dat dataset; if add more 
# species, will need to reprocess 
# Note: this generates 10x10km2 data; 1x1km2 data are too large to generate/store, 
# so run these for each species range of interest if necessary 


# Set workspace -----------------------------------------------------------------

setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/")
rm(list=ls()); gc()

library(terra)
library(stringr)
library(raster)
library(dplyr)
library(tidyr)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(arrow)
library(purrr)
library(parallel)
library(glmnet)
library(mgcv)
library(data.table)
library(ggplot2)
library(zoo)


## Load & format reference rasters --------------------------------------------

# Load reference rasters
ref_1km      <- rast("1x1 km spatial layers/reference_1km2.tif")
ref_10km     <- rast("10x10 km spatial layers/reference_10km2.tif")
species_rast <- rast("WI data/global_species_raster.tif")

# Crop reference rasters to species_raster
ref_1km_cell_ID  <- ref_1km[["cell_ID"]]
ref_10km_cell_ID <- ref_10km[["cell_ID"]]

reference_species_1km <- crop(ref_1km_cell_ID, ext(species_rast))
reference_species_1km <- mask(reference_species_1km, species_rast)  
reference_species_1km; plot(reference_species_1km)

reference_species_10km <- crop(ref_10km_cell_ID, species_rast)
presence <- project(species_rast, reference_species_10km, method = "max")
reference_species_10km <- mask(reference_species_10km, presence)
valid_ids <- values(reference_species_10km, na.rm = TRUE)
sum(duplicated(valid_ids))

# Create coordinate dataframe 
coords_1km  <- as.data.frame(reference_species_1km, xy=T)
coords_10km <- as.data.frame(reference_species_10km, xy=T) 


## Create period template -----------------------------------------------------

min_year <- 2000  
max_year <- 2024 
range_year <- c(min_year, max_year)
min_date <- as.Date(paste(range_year[1] - 1, "-12-01", sep = ""))
max_date <- as.Date(paste(range_year[2] + 1, "-03-01", sep = "")) 
start_period <-  seq.Date(min_date, max_date, by =  "91 day") #"3 month"
end_period <-  c(start_period[-1] - 1, NA)

periods <- data.frame(period = paste("Period", seq(1, length(start_period), by = 1), sep = "_"),
                      start_period = start_period, 
                      end_period = end_period) 
periods <- periods[-nrow(periods),]
periods$season <- rep(c("Winter", "Spring", "Summer", "Fall"), length.out = nrow(periods))
periods$year <- year(periods$start_period)
periods$period_counter <- 1:nrow(periods)
head(periods)


## Covariates: static (dim: ncell) ------------------------------------------

## 1km2 RESOLUTION ---

# Load static covariates
static_layers <- list(road_dens = rast("1x1 km spatial layers/road_full_1km2.tif"),
                      tri       = rast("1x1 km spatial layers/tri_1km2_on_ref_grid.tif"),
                      river_dist= rast("1x1 km spatial layers/riv_1km2_on_ref_grid.tif"),
                      coeff_var = rast("1x1 km spatial layers/cv_1km2_on_ref_grid.tif"),
                      cities_lg = rast("1x1 km spatial layers/ha_large_1km2_on_ref_grid.tif"))
r_c <- rast(static_layers)

# Crop and mask to the extent of mmd_raster 
r_c_species <-     crop(r_c, reference_species_1km)           
r_c_species <-     mask(r_c_species, reference_species_1km)  
full_stack <-      c(reference_species_1km, r_c_species) 

# Check for missing values
global(full_stack, fun = "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Covariates to impute
covs_to_impute <- names(valid_df)[5:ncol(valid_df)]

# Global means (fallback)
global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = covs_to_impute]
global_means <- as.numeric(global_means)
names(global_means) <- covs_to_impute

# Melt to long for efficient grouping
dt_long <- melt(valid_df, 
                id.vars = c("cell", "x", "y", "cell_ID"),
                measure.vars = covs_to_impute,
                variable.name = "covariate",
                value.name = "value")

# Add row-based blocks (for local trends)
res_y <- yres(full_stack)
dt_long[, row_idx := (ymax(full_stack) - y) / res_y + 1]   
block_size <- 500
dt_long[, block := ceiling(row_idx / block_size)]

# Impute block-wise  
dt_long[, value := {
  na_idx <- which(is.na(value))
  if (length(na_idx) == 0) {
    value
  } else {
    train <- .SD[!is.na(value), .(value, x, y)]
    if (nrow(train) < 3) {
      value[na_idx] <- global_means[.BY$covariate]
    } else {
      mod <- lm(value ~ x + y, data = train)
      preds <- predict(mod, newdata = .SD[na_idx, .(x, y)])
      value[na_idx] <- preds
      
      # Fallback
      still_na <- na_idx[is.na(value[na_idx])]
      if (length(still_na) > 0) value[still_na] <- global_means[.BY$covariate]
    }
    value
  }
}, by = .(block, covariate)]   

# Cast to wide
imputed_df <- dcast(dt_long, cell + cell_ID + x + y ~ covariate, value.var = "value")

# Save 
setorder(imputed_df, cell_ID)
imputed_df$cell <- NULL
fwrite(imputed_df[, .SD], "Covariates for modelling/site_level_covariates_1x1km2.csv")

# Plot to check 
cov_value <- "cities_lg"
ggplot(static_1km, aes(x = x, y = y, fill = .data[[cov_value]])) +
  geom_tile() +   
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## 10km2 RESOLUTION --- 

# Load static covariates
static_layers <- list(road_dens = rast("10x10 km spatial layers/road_dens_10km.tif"),
                      tri       = rast("10x10 km spatial layers/tri_10km.tif"),
                      river_dist= rast("10x10 km spatial layers/river_dist_10km.tif"),
                      coeff_var = rast("10x10 km spatial layers/coeff_var_10km.tif"),
                      cities_lg = rast("10x10 km spatial layers/cities_lg_10km.tif"))
r_c <- rast(static_layers)

# Crop and mask to the extent of mmd_raster 
r_c_species <-     crop(r_c, reference_species_10km)          
r_c_aligned <-     resample(r_c_species, reference_species_10km, method = "near",  
                            filename = "", overwrite = TRUE)
r_c_species <-     mask(r_c_aligned, reference_species_10km)  
full_stack <-      c(reference_species_10km, r_c_species) 

# Check for missing values
global(full_stack, fun = "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Covariates to impute
covs_to_impute <- names(valid_df)[5:ncol(valid_df)]

# Global means (fallback)
global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = covs_to_impute]
global_means <- as.numeric(global_means)
names(global_means) <- covs_to_impute

# Melt to long for efficient grouping
dt_long <- melt(valid_df, 
                id.vars = c("cell", "x", "y", "cell_ID"),
                measure.vars = covs_to_impute,
                variable.name = "covariate",
                value.name = "value")

# Add row-based blocks (for local trends)
res_y <- yres(full_stack)
dt_long[, row_idx := (ymax(full_stack) - y) / res_y + 1]   
block_size <- 500
dt_long[, block := ceiling(row_idx / block_size)]

# Impute block-wise  
dt_long[, value := {
  na_idx <- which(is.na(value))
  if (length(na_idx) == 0) {
    value
  } else {
    train <- .SD[!is.na(value), .(value, x, y)]
    if (nrow(train) < 3) {
      value[na_idx] <- global_means[.BY$covariate]
    } else {
      mod <- lm(value ~ x + y, data = train)
      preds <- predict(mod, newdata = .SD[na_idx, .(x, y)])
      value[na_idx] <- preds
      
      # Fallback
      still_na <- na_idx[is.na(value[na_idx])]
      if (length(still_na) > 0) value[still_na] <- global_means[.BY$covariate]
    }
    value
  }
}, by = .(block, covariate)]   

# Cast to wide
imputed_df <- dcast(dt_long, cell + cell_ID + x + y ~ covariate, value.var = "value")

# Save 
setorder(imputed_df, cell_ID)
imputed_df$cell <- NULL
fwrite(imputed_df[, .SD], "Covariates for modelling/site_level_covariates_10x10km2.csv")

# Plot to check 
static_10km <- fread("Covariates for modelling/site_level_covariates_10x10km2.csv")

cov_value <- "cities_lg"
ggplot(static_10km, aes(x = x, y = y, fill = .data[[cov_value]])) +
  geom_tile() +   
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## Annual dynamic layers: Seasonal precipitation ------------------------------

# WAITING ON DOWNLOADED WORLDCLIM DATA -- 


## Annual dynamic layers: Global world population (GPW) -----------------------

## 10km2 --- 

# Load TIF files 
gwp <- rast("10x10 km spatial layers/gwp_10km.tif")

# Crop, resample, mask
r_c_species <- crop(gwp, reference_species_10km)
r_c_aligned <- resample(r_c_species, reference_species_10km, method = "near")
r_c_species <- mask(r_c_aligned, reference_species_10km)
full_stack <- c(reference_species_10km, r_c_species)

# Check missing values raster-wide
global(full_stack, "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Isolate true NAs in valid cells per layer
cov_layers <- names(gwp)   
true_nas <- valid_df[, lapply(.SD, function(x) sum(is.na(x))), .SDcols = cov_layers]

#  Spatial imputation per observed year (global mean as fallback) 
if (any(true_nas > 0)) {
  message("Imputing spatial missing values per layer...")
  global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = cov_layers]
  global_means <- as.numeric(global_means)
  names(global_means) <- cov_layers
  
  for (cov in cov_layers) {
    na_idx <- which(is.na(valid_df[[cov]]))
    if (length(na_idx) == 0) next
    
    train <- valid_df[!is.na(get(cov)), .(value = get(cov), x, y)]
    if (nrow(train) < 3) {
      valid_df[na_idx, (cov) := global_means[cov]]
      next
    }
    
    mod <- lm(value ~ x + y, data = train)
    preds <- predict(mod, newdata = valid_df[na_idx, .(x, y)])
    valid_df[na_idx, (cov) := preds]
    
    # Fallback
    still_na <- na_idx[is.na(valid_df[[cov]][na_idx])]
    if (length(still_na) > 0) valid_df[still_na, (cov) := global_means[cov]]
  }
}

# Melt to long
dt_long <- melt(valid_df, 
                id.vars = c("cell_ID", "x", "y"),  
                measure.vars = cov_layers,
                variable.name = "layer",
                value.name = "cov_value")
dt_long[, year := as.integer(sub("GPW_", "", layer))]  

# Temporal imputation per cell_ID
# - Use linear interpolation (approx) between observed years
# - Constant extrapolation for years outside observed range
# - If only one observed year, all get that value

# Get ALL relevant years directly from periods (no hard-coded skips)
all_relevant_years <- sort(unique(periods$year))

# Interpolate / fill per cell_ID over exactly these years
interpolated_dt <- dt_long[, {
  if (.N == 0 || all(is.na(cov_value))) {
    data.table(year = all_relevant_years, cov_value = NA_real_)
  } else {
    # Remove any duplicate years (safety)
    unique_obs <- unique(.SD[!is.na(cov_value), .(year, cov_value)])
    setorder(unique_obs, year)
    
    # Linear interp + constant extrapolation
    filled <- approx(x    = unique_obs$year,
                     y    = unique_obs$cov_value,
                     xout = all_relevant_years,
                     rule = 2,           # constant extrapolation outside observed range
                     method = "linear")$y
    
    data.table(year = all_relevant_years, cov_value = filled)
  }
}, by = cell_ID]

# Safety: ensure no duplicate rows per cell_ID/year
interpolated_dt <- unique(interpolated_dt, by = c("cell_ID", "year"))
period_map <- unique(periods[, .(year, period_counter)])   

interpolated_with_period <- interpolated_dt[
  period_map,
  on = "year",
  allow.cartesian = TRUE
]

df_wide <- dcast(interpolated_with_period,
                 cell_ID ~ period_counter,
                 value.var = "cov_value")
setorder(df_wide, cell_ID)

# Convert to matrix  
df_mat <- as.matrix(df_wide, rownames = "cell_ID")

# Save full dataframe
fwrite(df_mat, "Covariates for modelling/GPW_covariate_10x10km2.csv")

# Plot to check 
setDT(coords_10km)
plot_df <- cbind(coords_10km[, .(x, y)], as.data.frame(df_mat))

ggplot(plot_df) +
  geom_tile(aes(x = x, y = y, fill = `99`), width = 10000, height = 10000) +
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## Annual dynamic layers: Enhanced vegetation index (EVI) ---------------------

## 10km2 --- 

# Load TIF files 
evi_files <- list.files("10x10 km spatial layers/EVI", full.names = TRUE)
evi_list_raster <- lapply(evi_files, rast)
evi_stack <- rast(evi_list_raster)
names(evi_stack) <- gsub(".{11}$", "", basename(evi_files))

# Extract mean values for each cell_ID across all rasters in the stack
evi_aligned <- crop(evi_stack, reference_species_10km)
evi_aligned <- mask(evi_aligned, reference_species_10km)
extracted <- terra::zonal(evi_aligned, reference_species_10km, fun = mean, na.rm = TRUE, df = TRUE)
extracted <- as.data.table(extracted)
head(extracted)

# Convert to long
setDT(extracted)
dt_long <- melt(extracted,
                id.vars = "cell_ID",
                variable.name = "date",
                value.name = "cov_value")
dt_long[, c("year", "doy") := tstrsplit(gsub("evi_", "", date), "_", fixed = TRUE)]
dt_long[, year := as.integer(year)]
dt_long[, doy  := as.integer(doy)]
dt_long[, obs_date := as.Date(doy - 1, origin = paste0(year, "-01-01"))]
dt_long[, date := NULL]

# Match with periods 
dt_long[, obs_start := as.IDate(obs_date)]
dt_long[, obs_end   := as.IDate(obs_date)]   
dt_long_test <- dt_long %>% select(-doy)
setcolorder(dt_long_test, c("obs_start", "obs_end", setdiff(names(dt_long_test), c("obs_start","obs_end"))))

periods <- setDT(periods)
periods[, start_period := as.IDate(start_period)]
periods[, end_period   := as.IDate(end_period)]
periods_test <- periods %>% select(-season, -period)

setkey(periods_test, start_period, end_period)
setkey(dt_long_test, obs_start, obs_end)

dt_long_test <- foverlaps(
  dt_long_test,     # y table
  periods_test,     # x table
  by.x = c("obs_start", "obs_end"),
  by.y = c("start_period", "end_period"),
  type = "within",  # only matches where obs_date is inside the period
  nomatch = NA     # keep unmatched rows as NA
)
dt_long_test <- dt_long_test %>% select(period_counter, year, cell_ID, cov_value)

dt_period <- dt_long_test[, .(
  cov_value = mean(cov_value, na.rm = TRUE)
), by = .(cell_ID, period_counter, year)]

# Ensure one row per cell_ID per period 
all_ids <- dt_period[, unique(cell_ID)]
all_periods <- unique(periods[, .(period_counter)])

# Cross join
full_grid <- CJ(cell_ID = unique(dt_period$cell_ID),        
                period_counter = unique(periods$period_counter))

# Add data
dt_complete <- merge(full_grid, dt_period,
                     by = c("cell_ID", "period_counter"),
                     all.x = TRUE)
dt_complete <- dt_complete[!is.na(dt_complete$cell_ID),]

# Fix weird issue 
unique(dt_complete[is.na(dt_complete$year),]$period_counter)
year <- periods[periods$period_counter == 55,]$year
dt_complete[dt_complete$period_counter == 55,]$year <- year

# Add coordinates
coords_10km <- setDT(coords_10km)
dt_complete <- coords_10km[dt_complete, on = "cell_ID"]

# Ridge regression imputation per year
impute_ridge_by_year <- function(dt) {
  dt[, cov_value := as.numeric(cov_value)]
  
  dt_imputed <- dt[, {
    this <- copy(.SD)    
    train <- this[!is.na(cov_value) & !is.nan(cov_value)]
    
    if (nrow(train) >= 3 && length(unique(train$cov_value)) > 1) {
      # design matrices
      X_train <- model.matrix(~ period_counter + x + y, train)[, -1]
      y_train <- train$cov_value
      
      fit <- cv.glmnet(
        X_train, y_train,
        alpha = 0,
        nfolds = min(5, nrow(train)),
        standardize = TRUE
      )
      
      X_all <- model.matrix(~ period_counter + x + y, this)[, -1]
      preds <- as.numeric(predict(fit, newx = X_all, s = "lambda.min"))
      
      # replace only missing
      this$cov_value <- fifelse(is.na(this$cov_value) | is.nan(this$cov_value),
                                preds, this$cov_value)
    }
    
    this   
  }, by = year]
  
  return(dt_imputed[])
}

dt_imputed <- impute_ridge_by_year(dt_complete)

# Pivot to final matrix
setkey(dt_imputed, cell_ID, period_counter)
EVI_mat <- dcast(dt_imputed,
                 cell_ID ~ period_counter,
                 value.var = "cov_value",
                 fill = NA_real_)

# Plot to check
selected_year <- "2007"
plot_subset <- dt_imputed %>% filter(year == selected_year)

ggplot(plot_subset, aes(x = x, y = y, fill = cov_value)) +
  geom_tile() + scale_fill_viridis_c(option = "magma") +
  coord_equal() + theme_minimal()

# Save full dataframe
fwrite(EVI_mat, "Covariates for modelling/EVI_covariate_10x10km2.csv")


## Proportion non-natural landcover, forest (CCI ESI) -------------------------

# LC classes 
forest_class <- c(50, 60, 61, 62, 70, 71, 72, 80, 81, 82, 90, 160, 170)
unnatural_areas <- c(10, 20, 30, 40, 190)

# Load TIF files 
lc_files <- list.files("Raw spatial layers/CCI landcover 1km2", pattern = "\\.tif$", 
                       full.names = TRUE)

years <- as.integer(sub(".*CCI_([0-9]{4})_REPRO\\.tif", "\\1", basename(lc_files)))
lc_files <- lc_files[years >= min(periods$year)]
r_stack <- rast(lc_files)

# Crop and mask to the extent of mmd_raster 
r_c_species <-     crop(r_stack, reference_species_10km)           
r_c_species <-     mask(r_c_species, reference_species_10km)  

# Add cell_IDs 
cell_id_species <- crop(global_cell_id, reference_species_10km)
cell_id_species <- mask(cell_id_species, reference_species_10km)
full_stack <-      c(cell_id_species, r_c_species)



# As data frame
landcover_df <-       as.data.frame(full_stack, na.rm = TRUE, xy=TRUE)

# Check cells in mmd
landcover_cells <- landcover_df %>% pull(cell_ID) %>% unique() %>% .[. %in% sites]
missing_in_landcover <- setdiff(sites, landcover_cells)
cat("Cells missing in landcover: ", length(missing_in_landcover), "\n")

# Melt to long 
setDT(landcover_df)  
landcover_long <- melt(landcover_df,
                       id.vars       = c("x", "y", "cell_ID"),
                       measure.vars  = grep("^CCI_[0-9]{4}_REPRO$", names(landcover_df), 
                                            value = TRUE),
                       variable.name = "year_var",
                       value.name    = "landcover_class")
setDT(landcover_long)
landcover_long[, year := as.integer(sub("^CCI_([0-9]{4})_REPRO$", "\\1", year_var))]
landcover_long[, year_var := NULL]
setorder(landcover_long, cell_ID, year)

# Create crop and forest columns 
landcover_long[, crop   := ifelse(landcover_class %in% crop_class,  1L, 0L)]
landcover_long[, forest := ifelse(landcover_class %in% forest_class, 1L, 0L)]
setDT(landcover_long)

# Define future years
future_years <- c(2023, 2024)

# Extrapolate by carrying forward last observed values per cell_ID
landcover_future <- landcover_long[, {
  last_row <- .SD[which.max(year)] 
  .(year = future_years,
    crop = last_row$crop,
    forest = last_row$forest)
}, by = .(x, y, cell_ID)]

# Combine observed + predicted 
landcover_full_long <- rbindlist(list(landcover_long[, .(x, y, cell_ID, year, crop, forest)], landcover_future), use.names = TRUE)
setorder(landcover_full_long, cell_ID, year)

# Join period_counter to each year 
landcover_data <- landcover_full_long[periods[, .(year, period_counter)], 
                                      on = "year", 
                                      allow.cartesian = TRUE]
setorder(landcover_data, cell_ID, year, period_counter)
head(landcover_data)

rm(landcover_full_long, landcover_future, landcover_long, landcover_df); gc()


## Proportion forest & proportion of unnatural areas (CCI ESI) ----------------



# Function to calculate proportions
calculate_proportion <- function(class_values, lc_raster, grid_raster) {
  binary_raster <- lc_raster %in% class_values
  clipped_grid  <- crop(grid_raster, binary_raster)
  clipped_grid  <- resample(clipped_grid, binary_raster, method = "near")
  
  df <- data.frame(cell_ID = as.vector(clipped_grid),
                   value   = as.vector(binary_raster)) %>% 
    filter(!is.na(cell_ID))
  
  prop_df <- df %>%
    group_by(cell_ID) %>%
    summarise(proportion = mean(value, na.rm = TRUE), .groups = "drop")
  
  return(prop_df)
}

years <- as.numeric(str_extract(basename(lc_files), "\\d{4}"))
lc_files <- list.files("CCI landcover 1km2")

# Process forest files 
class <- forest_class
class_name <- "forest_class"

prop_list <- lapply(seq_along(lc_files), function(i) {
  file <- paste0("CCI landcover 1km2/", lc_files[i])
  landcover <- rast(file)
  if (!compareGeom(landcover, reference_land, stopOnError = FALSE)) {
    landcover <- project(landcover, crs(reference_land), method="near")
  }
  prop_list <- calculate_proportion(class, landcover, reference_species_10km)
  prop_list$year <- years[i]
  prop_list
})
prop_all <- bind_rows(prop_list)
head(prop_all)

filename <- paste0("../10x10 km spatial layers/", class_name, "1993-2022.csv")
fwrite(crop_all, filename)



# === SIMPLE PREDICTION FOR 2023â€“2024 ===
forest_all <- merge(prop_all, coords, by.x = "cell_ID", by.y = "cell_ID", all.x = TRUE)

good_cells <- forest_all %>% group_by(cell_ID) %>% 
  filter(n() >= 8) %>% #cells with enough years of data to predict 
  pull(cell_ID) %>% unique()
forest_good <- filter(forest_all, cell_ID %in% good_cells)

predictions <- forest_good %>%
  group_by(cell_ID, x, y) %>%
  do({
    mod <- lm(proportion ~ year, data = .)                      
    data.frame(year = c(2023, 2024),
               proportion = predict(mod, newdata = data.frame(year = c(2023, 2024))))
  }) %>%
  ungroup()

poor_cells <- setdiff(forest_all$cell_ID, good_cells)
if (length(poor_cells) > 0) {
  last_vals <- forest_all %>%
    filter(cell_ID %in% poor_cells) %>%
    summarise(proportion = last(proportion), .by = cell_ID) %>%   # one row per cell
    uncount(2, .id = "tmp") %>%                                   # duplicate
    mutate(year = 2022 + tmp) %>%                                 # 2023 and 2024
    select(-tmp)
  predictions <- bind_rows(predictions, last_vals)
}

predictions$proportion <- pmax(0, pmin(1, predictions$proportion))

forest_final <- bind_rows(
  forest_all %>% dplyr::select(cell_ID, year, proportion),
  predictions %>% dplyr::select(cell_ID, year, proportion)) %>%
  mutate(proportion = pmax(0, pmin(1, proportion))) %>%    
  arrange(cell_ID, year)
head(forest_final)

write.csv(forest_final, "../10x10 km spatial layers/forest_proportion_1993_2024.csv", row.names = FALSE)






# Read crop file 
crop <- read.csv("crop_proportion_all_years_full_new.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = crop_prop) %>% 
  distinct()

CROP_joined <- crop %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

# Plot to check  
selected_year <- 1999

plot_subset <- crop %>% filter(year == selected_year) 
ggplot(plot_subset, aes(x = x, y = y, fill = cov_value)) +
  geom_tile() + scale_fill_viridis_c(option = "magma") +
  coord_equal() + theme_minimal()

# Save full dataframe 
write.csv(CROP_joined, "../Covariates for modelling/primary_occ_covariates_crop_full.csv", row.names=F)

# Subset to sites 
subset_mat <- CROP_joined[CROP_joined[, "cell_ID"] %in% site_cells$cell_ID,]
write.csv(subset_mat, "../Covariates for modelling/primary_occ_covariates_crop_sites.csv", row.names=F)

## Read urban file 
urban <- read.csv("urban_proportion_all_years.csv") %>% 
  filter(year %in% periods$year) %>% 
  rename(cov_value = proportion) %>% 
  distinct()

URBAN_joined <- urban %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, cov_value) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = cov_value, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

write.csv(URBAN_joined, "primary_occ_covariates_urban.csv", row.names=F)


## Proportion of cell in protected area (WDPA) --------------------------------

# Read WDPA file  
wdpa <- read.csv("prop_wdpa_full.csv")

WDPA_joined <- wdpa %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, prop_in_PA) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = prop_in_PA, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

head(WDPA_joined)

# Plot to check  
selected_year <- 2006
plot_subset <- wdpa %>% filter(year == selected_year) %>% 
  left_join(coords, by = "cell_ID")

ggplot(plot_subset, aes(x = x, y = y, fill = prop_in_PA)) +
  geom_tile() + scale_fill_viridis_c(option = "magma") +
  coord_equal() + theme_minimal()

# Save full dataframe 
write.csv(WDPA_joined, "../Covariates for modelling/primary_occ_covariates_WDPA_full.csv", row.names=F)

# Subset to sites 
head(WDPA_joined)
subset_mat <- WDPA_joined[WDPA_joined[, "cell_ID"] %in% site_cells$cell_ID, ]
write.csv(subset_mat, "../Covariates for modelling/primary_occ_covariates_WDPA_sites.csv", row.names=F)





# WPDA 

################################################################################
### Prop WDPA ##################################################################
################################################################################

# Calculates the proportion of each grid cell contained within a WDPA polygon

setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/Raw spatial layers/WDPA_Jan2025_Public_shp")
rm(list=ls()); gc()

library(terra)
library(sf)
library(rnaturalearth)
library(dplyr)
library(tidyr)

# Create and load reference rasters with all site ids -------------------------

# All terrestrial areas 
reference <- reference <- rast("../../10x10 km spatial layers/raster_100km2_with_cellID.tif")
land <- ne_countries(scale = "medium", returnclass = "sf")
land_terra <- vect(land)
if (crs(reference) != crs(land_terra)) {land_terra <- project(land_terra, crs(reference))}
reference_land <- mask(reference, land_terra)

# NOTE some sites not captured in land mask -- add manually 
site_cells <- read.csv("../../10x10 km spatial layers/WI_loc_matching_cell_ID.csv") 
existing_ids <- reference_land$cell_ID
missing_ids <- setdiff(site_cells$cell_ID, existing_ids)
add_raster <- reference
add_raster[!values(add_raster) %in% missing_ids] <- NA
reference_land <- cover(reference_land, add_raster)

# Create 1km2 raster
ref_1km <- rast("../../Raw spatial layers/Global_1km_CEA_reference_raster.tif") 

# Load and format WDPA polygons -----------------------------------------------
shape1 <- st_read("WDPA_Jan2025_Public_shp_0/WDPA_Jan2025_Public_shp-polygons.shp")
shape2 <- st_read("WDPA_Jan2025_Public_shp_1/WDPA_Jan2025_Public_shp-polygons.shp")
shape3 <- st_read("WDPA_Jan2025_Public_shp_2/WDPA_Jan2025_Public_shp-polygons.shp")
wdpa <- rbind(shape1, shape2, shape3)
wdpa <- st_transform(wdpa, crs(ref_1km))

# Rasterize and extract protected area proportions ----------------------------
years <- 1999:2024
results_list <- vector("list", length(years))

for (i in seq_along(years)) {
  yr <- years[i]
  wdpa_yr <- wdpa %>% filter(STATUS_YR <= yr)
  
  r1_pa <- rasterize(vect(wdpa_yr), ref_1km, field=1, touches=TRUE)
  r1_pa[is.na(r1_pa)] <- 0  # convert NA to 0
  
  # Use nearest assignment: each 1km cell inherits ID of 10km cell it falls in
  r1_id <- resample(reference_land, ref_1km, method="near")
  
  # Extract values as data frame
  df <- data.frame(
    cell_ID = as.vector(r1_id$cell_ID),
    inPA   = as.vector(r1_pa$layer)) 
  sum(is.na(df$cell_ID))
  
  # Proportion of 1km cells inside PA per 10km cell
  summary_df <- df %>%
    group_by(cell_ID) %>%
    summarise(prop_in_PA = mean(inPA, na.rm=TRUE)) %>% 
    mutate(year = yr)
  
  results_list[[i]] <- summary_df
}

results_df <- dplyr::bind_rows(results_list)
head(results_df); unique(results_df$year)

write.csv(results_df, "/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/10x10 km spatial layers/prop_wdpa_full_new.csv", row.names=F)



