#############################################
### Extract static and dynamic covariates ###
#############################################

# This file contains code to create a preannotated version of the covariates for 
# the occupancy models. The types of covariates are: 

# * site-level covariates (static). Format: cells x 1 column per each covariate;
# * primary period-level covariates (dynamic). Format: cells x periods per each covariate. 
#       Some of these covariates (e.g. year) will have the repeated values in more than 
#       one column

# Run 1x

# Note: this extracts values species present in all_dat dataset; if add more 
# species, will need to reprocess 
# Note: this generates 10x10km2 data; 1x1km2 data are too large to generate/store, 
# so run these for each species range of interest if necessary 


# Set workspace -----------------------------------------------------------------

setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/")
rm(list=ls()); gc()

library(terra)
library(stringr)
library(raster)
library(dplyr)
library(tidyr)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(arrow)
library(purrr)
library(parallel)
library(glmnet)
library(mgcv)
library(data.table)
library(ggplot2)
library(zoo)


## Load & format reference rasters --------------------------------------------

# Load reference rasters
ref_1km      <- rast("1x1 km spatial layers/reference_1km2.tif")
ref_10km     <- rast("10x10 km spatial layers/reference_10km2.tif")
species_rast <- rast("WI data/global_species_raster.tif")

# Crop reference rasters to species_raster
ref_1km_cell_ID  <- ref_1km[["cell_ID"]]
ref_10km_cell_ID <- ref_10km[["cell_ID"]]

reference_species_1km <- crop(ref_1km_cell_ID, ext(species_rast))
reference_species_1km <- mask(reference_species_1km, species_rast)  
reference_species_1km; plot(reference_species_1km)

reference_species_10km <- crop(ref_10km_cell_ID, species_rast)
presence <- project(species_rast, reference_species_10km, method = "max")
reference_species_10km <- mask(reference_species_10km, presence)
valid_ids <- values(reference_species_10km, na.rm = TRUE)
sum(duplicated(valid_ids))

# Create coordinate dataframe 
coords_1km  <- as.data.frame(reference_species_1km, xy=T)
coords_10km <- as.data.frame(reference_species_10km, xy=T) 


## Create period template -----------------------------------------------------

min_year <- 2000  
max_year <- 2024 
range_year <- c(min_year, max_year)
min_date <- as.Date(paste(range_year[1] - 1, "-12-01", sep = ""))
max_date <- as.Date(paste(range_year[2] + 1, "-03-01", sep = "")) 
start_period <-  seq.Date(min_date, max_date, by =  "91 day") #"3 month"
end_period <-  c(start_period[-1] - 1, NA)

periods <- data.frame(period = paste("Period", seq(1, length(start_period), by = 1), sep = "_"),
                      start_period = start_period, 
                      end_period = end_period) 
periods <- periods[-nrow(periods),]
periods$season <- rep(c("Winter", "Spring", "Summer", "Fall"), length.out = nrow(periods))
periods$year <- year(periods$start_period)
periods$period_counter <- 1:nrow(periods)
head(periods)


## Covariates: static (dim: ncell) ------------------------------------------

## 1km2 RESOLUTION ---

# Load static covariates
static_layers <- list(road_dens = rast("1x1 km spatial layers/road_full_1km2.tif"),
                      tri       = rast("1x1 km spatial layers/tri_1km2_on_ref_grid.tif"),
                      river_dist= rast("1x1 km spatial layers/riv_1km2_on_ref_grid.tif"),
                      coeff_var = rast("1x1 km spatial layers/cv_1km2_on_ref_grid.tif"),
                      cities_lg = rast("1x1 km spatial layers/ha_large_1km2_on_ref_grid.tif"))
r_c <- rast(static_layers)

# Crop and mask to the extent of mmd_raster 
r_c_species <-     crop(r_c, reference_species_1km)           
r_c_species <-     mask(r_c_species, reference_species_1km)  
full_stack <-      c(reference_species_1km, r_c_species) 

# Check for missing values
global(full_stack, fun = "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Covariates to impute
covs_to_impute <- names(valid_df)[5:ncol(valid_df)]

# Global means (fallback)
global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = covs_to_impute]
global_means <- as.numeric(global_means)
names(global_means) <- covs_to_impute

# Melt to long for efficient grouping
dt_long <- melt(valid_df, 
                id.vars = c("cell", "x", "y", "cell_ID"),
                measure.vars = covs_to_impute,
                variable.name = "covariate",
                value.name = "value")

# Add row-based blocks (for local trends)
res_y <- yres(full_stack)
dt_long[, row_idx := (ymax(full_stack) - y) / res_y + 1]   
block_size <- 500
dt_long[, block := ceiling(row_idx / block_size)]

# Impute block-wise  
dt_long[, value := {
  na_idx <- which(is.na(value))
  if (length(na_idx) == 0) {
    value
  } else {
    train <- .SD[!is.na(value), .(value, x, y)]
    if (nrow(train) < 3) {
      value[na_idx] <- global_means[.BY$covariate]
    } else {
      mod <- lm(value ~ x + y, data = train)
      preds <- predict(mod, newdata = .SD[na_idx, .(x, y)])
      value[na_idx] <- preds
      
      # Fallback
      still_na <- na_idx[is.na(value[na_idx])]
      if (length(still_na) > 0) value[still_na] <- global_means[.BY$covariate]
    }
    value
  }
}, by = .(block, covariate)]   

# Cast to wide
imputed_df <- dcast(dt_long, cell + cell_ID + x + y ~ covariate, value.var = "value")

# Save 
setorder(imputed_df, cell_ID)
imputed_df$cell <- NULL
fwrite(imputed_df[, .SD], "Covariates for modelling/site_level_covariates_1x1km2.csv")

# Plot to check 
cov_value <- "cities_lg"
ggplot(static_1km, aes(x = x, y = y, fill = .data[[cov_value]])) +
  geom_tile() +   
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## 10km2 RESOLUTION --- 

# Load static covariates
static_layers <- list(road_dens = rast("10x10 km spatial layers/road_dens_10km.tif"),
                      tri       = rast("10x10 km spatial layers/tri_10km.tif"),
                      river_dist= rast("10x10 km spatial layers/river_dist_10km.tif"),
                      coeff_var = rast("10x10 km spatial layers/coeff_var_10km.tif"),
                      cities_lg = rast("10x10 km spatial layers/cities_lg_10km.tif"))
r_c <- rast(static_layers)

# Crop and mask to the extent of mmd_raster 
r_c_species <-     crop(r_c, reference_species_10km)          
r_c_aligned <-     resample(r_c_species, reference_species_10km, method = "near",  
                            filename = "", overwrite = TRUE)
r_c_species <-     mask(r_c_aligned, reference_species_10km)  
full_stack <-      c(reference_species_10km, r_c_species) 

# Check for missing values
global(full_stack, fun = "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Covariates to impute
covs_to_impute <- names(valid_df)[5:ncol(valid_df)]

# Global means (fallback)
global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = covs_to_impute]
global_means <- as.numeric(global_means)
names(global_means) <- covs_to_impute

# Melt to long for efficient grouping
dt_long <- melt(valid_df, 
                id.vars = c("cell", "x", "y", "cell_ID"),
                measure.vars = covs_to_impute,
                variable.name = "covariate",
                value.name = "value")

# Add row-based blocks (for local trends)
res_y <- yres(full_stack)
dt_long[, row_idx := (ymax(full_stack) - y) / res_y + 1]   
block_size <- 500
dt_long[, block := ceiling(row_idx / block_size)]

# Impute block-wise  
dt_long[, value := {
  na_idx <- which(is.na(value))
  if (length(na_idx) == 0) {
    value
  } else {
    train <- .SD[!is.na(value), .(value, x, y)]
    if (nrow(train) < 3) {
      value[na_idx] <- global_means[.BY$covariate]
    } else {
      mod <- lm(value ~ x + y, data = train)
      preds <- predict(mod, newdata = .SD[na_idx, .(x, y)])
      value[na_idx] <- preds
      
      # Fallback
      still_na <- na_idx[is.na(value[na_idx])]
      if (length(still_na) > 0) value[still_na] <- global_means[.BY$covariate]
    }
    value
  }
}, by = .(block, covariate)]   

# Cast to wide
imputed_df <- dcast(dt_long, cell + cell_ID + x + y ~ covariate, value.var = "value")

# Save 
setorder(imputed_df, cell_ID)
imputed_df$cell <- NULL
fwrite(imputed_df[, .SD], "Covariates for modelling/site_level_covariates_10x10km2.csv")

# Plot to check 
static_10km <- fread("Covariates for modelling/site_level_covariates_10x10km2.csv")

cov_value <- "cities_lg"
ggplot(static_10km, aes(x = x, y = y, fill = .data[[cov_value]])) +
  geom_tile() +   
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## Annual dynamic layers: Seasonal precipitation ------------------------------

# WAITING ON DOWNLOADED WORLDCLIM DATA -- 


## Annual dynamic layers: Global world population (GPW) -----------------------

## 10km2 --- 

# Load TIF files 
gwp <- rast("10x10 km spatial layers/gwp_10km.tif")

# Crop, resample, mask
r_c_species <- crop(gwp, reference_species_10km)
r_c_aligned <- resample(r_c_species, reference_species_10km, method = "near")
r_c_species <- mask(r_c_aligned, reference_species_10km)
full_stack <- c(reference_species_10km, r_c_species)

# Check missing values raster-wide
global(full_stack, "isNA")

# Extract valid data 
df <- as.data.frame(full_stack, na.rm = FALSE, cells = TRUE, xy = TRUE)
setDT(df)
valid_df <- df[!is.na(cell_ID)]

# Isolate true NAs in valid cells per layer
cov_layers <- names(gwp)   
true_nas <- valid_df[, lapply(.SD, function(x) sum(is.na(x))), .SDcols = cov_layers]

#  Spatial imputation per observed year (global mean as fallback) 
if (any(true_nas > 0)) {
  message("Imputing spatial missing values per layer...")
  global_means <- valid_df[, lapply(.SD, mean, na.rm = TRUE), .SDcols = cov_layers]
  global_means <- as.numeric(global_means)
  names(global_means) <- cov_layers
  
  for (cov in cov_layers) {
    na_idx <- which(is.na(valid_df[[cov]]))
    if (length(na_idx) == 0) next
    
    train <- valid_df[!is.na(get(cov)), .(value = get(cov), x, y)]
    if (nrow(train) < 3) {
      valid_df[na_idx, (cov) := global_means[cov]]
      next
    }
    
    mod <- lm(value ~ x + y, data = train)
    preds <- predict(mod, newdata = valid_df[na_idx, .(x, y)])
    valid_df[na_idx, (cov) := preds]
    
    # Fallback
    still_na <- na_idx[is.na(valid_df[[cov]][na_idx])]
    if (length(still_na) > 0) valid_df[still_na, (cov) := global_means[cov]]
  }
}

# Melt to long
dt_long <- melt(valid_df, 
                id.vars = c("cell_ID", "x", "y"),  
                measure.vars = cov_layers,
                variable.name = "layer",
                value.name = "cov_value")
dt_long[, year := as.integer(sub("GPW_", "", layer))]  

# Temporal imputation per cell_ID
# - Use linear interpolation (approx) between observed years
# - Constant extrapolation for years outside observed range
# - If only one observed year, all get that value

# Get ALL relevant years directly from periods (no hard-coded skips)
all_relevant_years <- sort(unique(periods$year))

# Interpolate / fill per cell_ID over exactly these years
interpolated_dt <- dt_long[, {
  if (.N == 0 || all(is.na(cov_value))) {
    data.table(year = all_relevant_years, cov_value = NA_real_)
  } else {
    # Remove any duplicate years (safety)
    unique_obs <- unique(.SD[!is.na(cov_value), .(year, cov_value)])
    setorder(unique_obs, year)
    
    # Linear interp + constant extrapolation
    filled <- approx(x    = unique_obs$year,
                     y    = unique_obs$cov_value,
                     xout = all_relevant_years,
                     rule = 2,           # constant extrapolation outside observed range
                     method = "linear")$y
    
    data.table(year = all_relevant_years, cov_value = filled)
  }
}, by = cell_ID]

# Safety: ensure no duplicate rows per cell_ID/year
interpolated_dt <- unique(interpolated_dt, by = c("cell_ID", "year"))
period_map <- unique(periods[, .(year, period_counter)])   

interpolated_with_period <- interpolated_dt[
  period_map,
  on = "year",
  allow.cartesian = TRUE
]

df_wide <- dcast(interpolated_with_period,
                 cell_ID ~ period_counter,
                 value.var = "cov_value")
setorder(df_wide, cell_ID)

# Convert to matrix  
df_mat <- as.matrix(df_wide, rownames = "cell_ID")

# Save full dataframe
fwrite(df_mat, "Covariates for modelling/GPW_covariate_10x10km2.csv")

# Plot to check 
setDT(coords_10km)
plot_df <- cbind(coords_10km[, .(x, y)], as.data.frame(df_mat))

ggplot(plot_df) +
  geom_tile(aes(x = x, y = y, fill = `99`), width = 10000, height = 10000) +
  scale_fill_viridis_c(option = "magma") +
  coord_equal() +
  theme_minimal()


## Annual dynamic layers: Enhanced vegetation index (EVI) ---------------------

## 10km2 --- 

# Load TIF files 
evi_files <- list.files("10x10 km spatial layers/EVI", full.names = TRUE)
evi_list_raster <- lapply(evi_files, rast)
evi_stack <- rast(evi_list_raster)
names(evi_stack) <- gsub(".{11}$", "", basename(evi_files))

# Extract mean values for each cell_ID across all rasters in the stack
evi_aligned <- crop(evi_stack, reference_species_10km)
evi_aligned <- mask(evi_aligned, reference_species_10km)
extracted <- terra::zonal(evi_aligned, reference_species_10km, fun = mean, na.rm = TRUE, df = TRUE)
extracted <- as.data.table(extracted)
head(extracted)

# Convert to long
setDT(extracted)
dt_long <- melt(extracted,
                id.vars = "cell_ID",
                variable.name = "date",
                value.name = "cov_value")
dt_long[, c("year", "doy") := tstrsplit(gsub("evi_", "", date), "_", fixed = TRUE)]
dt_long[, year := as.integer(year)]
dt_long[, doy  := as.integer(doy)]
dt_long[, obs_date := as.Date(doy - 1, origin = paste0(year, "-01-01"))]
dt_long[, date := NULL]

# Match with periods 
dt_long[, obs_start := as.IDate(obs_date)]
dt_long[, obs_end   := as.IDate(obs_date)]   
dt_long_test <- dt_long %>% select(-doy)
setcolorder(dt_long_test, c("obs_start", "obs_end", setdiff(names(dt_long_test), c("obs_start","obs_end"))))

periods <- setDT(periods)
periods[, start_period := as.IDate(start_period)]
periods[, end_period   := as.IDate(end_period)]
periods_test <- periods %>% select(-season, -period)

setkey(periods_test, start_period, end_period)
setkey(dt_long_test, obs_start, obs_end)

dt_long_test <- foverlaps(
  dt_long_test,     # y table
  periods_test,     # x table
  by.x = c("obs_start", "obs_end"),
  by.y = c("start_period", "end_period"),
  type = "within",  # only matches where obs_date is inside the period
  nomatch = NA     # keep unmatched rows as NA
)
dt_long_test <- dt_long_test %>% select(period_counter, year, cell_ID, cov_value)

dt_period <- dt_long_test[, .(
  cov_value = mean(cov_value, na.rm = TRUE)
), by = .(cell_ID, period_counter, year)]

# Ensure one row per cell_ID per period 
all_ids <- dt_period[, unique(cell_ID)]
all_periods <- unique(periods[, .(period_counter)])

# Cross join
full_grid <- CJ(cell_ID = unique(dt_period$cell_ID),        
                period_counter = unique(periods$period_counter))

# Add data
dt_complete <- merge(full_grid, dt_period,
                     by = c("cell_ID", "period_counter"),
                     all.x = TRUE)
dt_complete <- dt_complete[!is.na(dt_complete$cell_ID),]

# Fix weird issue 
unique(dt_complete[is.na(dt_complete$year),]$period_counter)
year <- periods[periods$period_counter == 55,]$year
dt_complete[dt_complete$period_counter == 55,]$year <- year

# Add coordinates
coords_10km <- setDT(coords_10km)
dt_complete <- coords_10km[dt_complete, on = "cell_ID"]

# Ridge regression imputation per year
impute_ridge_by_year <- function(dt) {
  dt[, cov_value := as.numeric(cov_value)]
  
  dt_imputed <- dt[, {
    this <- copy(.SD)    
    train <- this[!is.na(cov_value) & !is.nan(cov_value)]
    
    if (nrow(train) >= 3 && length(unique(train$cov_value)) > 1) {
      # design matrices
      X_train <- model.matrix(~ period_counter + x + y, train)[, -1]
      y_train <- train$cov_value
      
      fit <- cv.glmnet(
        X_train, y_train,
        alpha = 0,
        nfolds = min(5, nrow(train)),
        standardize = TRUE
      )
      
      X_all <- model.matrix(~ period_counter + x + y, this)[, -1]
      preds <- as.numeric(predict(fit, newx = X_all, s = "lambda.min"))
      
      # replace only missing
      this$cov_value <- fifelse(is.na(this$cov_value) | is.nan(this$cov_value),
                                preds, this$cov_value)
    }
    
    this   
  }, by = year]
  
  return(dt_imputed[])
}

dt_imputed <- impute_ridge_by_year(dt_complete)

# Pivot to final matrix
setkey(dt_imputed, cell_ID, period_counter)
EVI_mat <- dcast(dt_imputed,
                 cell_ID ~ period_counter,
                 value.var = "cov_value",
                 fill = NA_real_)

# Plot to check
selected_year <- "2007"
plot_subset <- dt_imputed %>% filter(year == selected_year)

ggplot(plot_subset, aes(x = x, y = y, fill = cov_value)) +
  geom_tile() + scale_fill_viridis_c(option = "magma") +
  coord_equal() + theme_minimal()

# Save full dataframe
fwrite(EVI_mat, "Covariates for modelling/EVI_covariate_10x10km2.csv")

# Clean up 
rm(plot_subset, EVI_mat, dt_imputed, dt_complete, full_grid, dt_period, dt_long_test)
gc()


## Proportion non-natural landcover, forest (CCI ESI) -------------------------

# LC classes 
forest_class <- c(50, 60, 61, 62, 70, 71, 72, 80, 81, 82, 90, 160, 170)
unnatural_areas <- c(10, 20, 30, 40, 190)

# Load TIF files 
lc_files <- list.files("Raw spatial layers/CCI landcover 1km2", pattern = "\\.tif$", 
                       full.names = TRUE)

years <- as.integer(sub(".*CCI_([0-9]{4})_REPRO\\.tif", "\\1", basename(lc_files)))
lc_files <- lc_files[years >= min(periods$year)]
r_stack <- rast(lc_files)

# Extract years from layer names
years <- as.integer(sub(".*CCI_([0-9]{4})_REPRO\\.tif", "\\1", sources(r_stack)))

# Get extent of reference raster and extend by 10km buffer
ext_ref <- ext(reference_species_10km)
ext_crop <- extend(ext_ref, c(10000, 10000, 10000, 10000)) 

# Crop the stack to the buffered extent to optimize processing
r_stack_cropped <- crop(r_stack, ext_crop)

# Prepare reclassification matrices 
forest_rcl <- matrix(c(forest_class, rep(1, length(forest_class))), ncol = 2)
unnatural_rcl <- matrix(c(unnatural_areas, rep(1, length(unnatural_areas))), ncol = 2)

# List to store results
results <- list()

# Loop over each year/layer
for (i in seq_len(nlyr(r_stack_cropped))) {
  lyr <- r_stack_cropped[[i]]
  
  # Reclassify for forest (1 if in forest_class, 0 otherwise)
  forest_lyr <- classify(lyr, forest_rcl, others = 0)
  
  # Reclassify for unnatural areas (1 if in unnatural_areas, 0 otherwise)
  unnatural_lyr <- classify(lyr, unnatural_rcl, others = 0)
  
  # Resample to 10km resolution using average (proportion)
  forest_prop <- resample(forest_lyr, reference_species_10km, method = "average")
  unnatural_prop <- resample(unnatural_lyr, reference_species_10km, method = "average")
  
  # Set clean names on the SpatRaster objects
  names(forest_prop) <- "prop_forest"
  names(unnatural_prop) <- "prop_unnatural"
  
  # Create data frame for this year
  df <- data.frame(
    cell_ID = values(reference_species_10km),
    year = years[i],
    prop_forest = values(forest_prop),
    prop_unnatural = values(unnatural_prop)
  )
  
  # Remove rows where cell_ID is NA (if any)
  df <- df[!is.na(df$cell_ID), ]
  
  results[[i]] <- df
}

# Combine all years into one data frame
final_df <- do.call(rbind, results)

# Extract coordinates for each cell_ID
ref_vals <- values(reference_species_10km)
valid_cells <- which(!is.na(ref_vals))
coords <- xyFromCell(reference_species_10km, valid_cells)
cell_coords <- data.frame(cell_ID = ref_vals[valid_cells],
                          x = coords[, "x"],
                          y = coords[, "y"])
final_df <- left_join(final_df, cell_coords, by = "cell_ID")

# Predict for 2023, 2024 
future_years <- c(2023, 2024)

predictions <- final_df %>%
  group_by(cell_ID) %>%
  do({
    df <- .
    
    # For prop_forest: linear model
    if (n_distinct(df$prop_forest) > 1) {  # Only fit if there's variation
      mod_f <- lm(prop_forest ~ year, data = df)
      pred_f <- predict(mod_f, newdata = data.frame(year = future_years))
    } else {
      pred_f <- rep(df$prop_forest[1], length(future_years))  # Constant if no variation
    }
    pred_f <- pmax(0, pmin(1, pred_f))  # Constrain to [0,1]
    
    # For prop_unnatural: same approach
    if (n_distinct(df$prop_unnatural) > 1) {
      mod_u <- lm(prop_unnatural ~ year, data = df)
      pred_u <- predict(mod_u, newdata = data.frame(year = future_years))
    } else {
      pred_u <- rep(df$prop_unnatural[1], length(future_years))
    }
    pred_u <- pmax(0, pmin(1, pred_u))  # Constrain to [0,1]
    
    # Return data.frame with predictions
    data.frame(
      year = future_years,
      prop_forest = pred_f,
      prop_unnatural = pred_u
    )
  }) %>%
  ungroup()

# Combine observed data with predictions
full_df <- bind_rows(final_df, predictions)
full_df <- setDT(full_df)

# Set periods 
setDT(periods)
periods_light <- periods[, .(period_counter, year)]

# Cross-join 
full_expanded <- CJ(cell_ID = unique(full_df$cell_ID),
                    period_counter = periods_light$period_counter)

# Include year 
full_expanded <- merge(full_expanded,
                       periods_light,
                       by = "period_counter",
                       all.x = TRUE)

# Join the observed/predicted proportions by cell_ID + year
full_with_periods <- merge(full_expanded,
                           full_df[, .(cell_ID, year, prop_forest, prop_unnatural)],
                           by = c("cell_ID", "year"),
                           all.x = TRUE)
setorder(full_with_periods, cell_ID, period_counter)

# Join 
full_with_periods_df <- full_df %>%
  select(cell_ID, year, prop_forest, prop_unnatural, x, y) %>%
  right_join(periods %>% select(period_counter, year),
             by = "year",
             relationship = "many-to-many") %>%
  arrange(cell_ID, period_counter)

# Convert to matrix
df_wide_forest <- dcast(full_with_periods_df,
                 cell_ID ~ period_counter,
                 value.var = "prop_forest")
setorder(df_wide_forest, cell_ID)
df_mat_forest <- as.matrix(df_wide_forest, rownames = "cell_ID")

df_wide_unnatural <- dcast(full_with_periods_df,
                        cell_ID ~ period_counter,
                        value.var = "prop_unnatural")
setorder(df_wide_unnatural, cell_ID)
df_mat_unnatural <- as.matrix(df_wide_unnatural, rownames = "cell_ID")

# Save 
fwrite(df_mat_forest, "Covariates for modelling/forest_covariate_10x10km2.csv")
fwrite(df_mat_unnatural, "Covariates for modelling/unnatural_covariate_10x10km2.csv")

# Clean up 
rm(final_df, predictions, full_df, full_expanded, full_with_periods, full_with_periods_df, df_wide_forest, df_wide_unnatural, df_mat_forest, df_mat_unnatural)
gc()


## Proportion of cell in protected area (WDPA) --------------------------------

# Read WDPA file  
wdpa <- read.csv("prop_wdpa_full.csv")

WDPA_joined <- wdpa %>%
  left_join(periods, relationship = "many-to-many") %>% 
  dplyr::select(cell_ID, period_counter, prop_in_PA) %>% 
  pivot_wider(id_cols = cell_ID, names_from = period_counter, values_from = prop_in_PA, 
              values_fill = NA) %>%
  arrange(cell_ID) %>% 
  as.matrix()

head(WDPA_joined)

# Plot to check  
selected_year <- 2006
plot_subset <- wdpa %>% filter(year == selected_year) %>% 
  left_join(coords, by = "cell_ID")

ggplot(plot_subset, aes(x = x, y = y, fill = prop_in_PA)) +
  geom_tile() + scale_fill_viridis_c(option = "magma") +
  coord_equal() + theme_minimal()

# Save full dataframe 
write.csv(WDPA_joined, "../Covariates for modelling/primary_occ_covariates_WDPA_full.csv", row.names=F)

# Subset to sites 
head(WDPA_joined)
subset_mat <- WDPA_joined[WDPA_joined[, "cell_ID"] %in% site_cells$cell_ID, ]
write.csv(subset_mat, "../Covariates for modelling/primary_occ_covariates_WDPA_sites.csv", row.names=F)





# WPDA 

################################################################################
### Prop WDPA ##################################################################
################################################################################

# Calculates the proportion of each grid cell contained within a WDPA polygon

setwd("/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/Raw spatial layers/WDPA_Jan2025_Public_shp")
rm(list=ls()); gc()

library(terra)
library(sf)
library(rnaturalearth)
library(dplyr)
library(tidyr)

# Create and load reference rasters with all site ids -------------------------

# All terrestrial areas 
reference <- reference <- rast("../../10x10 km spatial layers/raster_100km2_with_cellID.tif")
land <- ne_countries(scale = "medium", returnclass = "sf")
land_terra <- vect(land)
if (crs(reference) != crs(land_terra)) {land_terra <- project(land_terra, crs(reference))}
reference_land <- mask(reference, land_terra)

# NOTE some sites not captured in land mask -- add manually 
site_cells <- read.csv("../../10x10 km spatial layers/WI_loc_matching_cell_ID.csv") 
existing_ids <- reference_land$cell_ID
missing_ids <- setdiff(site_cells$cell_ID, existing_ids)
add_raster <- reference
add_raster[!values(add_raster) %in% missing_ids] <- NA
reference_land <- cover(reference_land, add_raster)

# Create 1km2 raster
ref_1km <- rast("../../Raw spatial layers/Global_1km_CEA_reference_raster.tif") 

# Load and format WDPA polygons -----------------------------------------------
shape1 <- st_read("WDPA_Jan2025_Public_shp_0/WDPA_Jan2025_Public_shp-polygons.shp")
shape2 <- st_read("WDPA_Jan2025_Public_shp_1/WDPA_Jan2025_Public_shp-polygons.shp")
shape3 <- st_read("WDPA_Jan2025_Public_shp_2/WDPA_Jan2025_Public_shp-polygons.shp")
wdpa <- rbind(shape1, shape2, shape3)
wdpa <- st_transform(wdpa, crs(ref_1km))

# Rasterize and extract protected area proportions ----------------------------
years <- 1999:2024
results_list <- vector("list", length(years))

for (i in seq_along(years)) {
  yr <- years[i]
  wdpa_yr <- wdpa %>% filter(STATUS_YR <= yr)
  
  r1_pa <- rasterize(vect(wdpa_yr), ref_1km, field=1, touches=TRUE)
  r1_pa[is.na(r1_pa)] <- 0  # convert NA to 0
  
  # Use nearest assignment: each 1km cell inherits ID of 10km cell it falls in
  r1_id <- resample(reference_land, ref_1km, method="near")
  
  # Extract values as data frame
  df <- data.frame(
    cell_ID = as.vector(r1_id$cell_ID),
    inPA   = as.vector(r1_pa$layer)) 
  sum(is.na(df$cell_ID))
  
  # Proportion of 1km cells inside PA per 10km cell
  summary_df <- df %>%
    group_by(cell_ID) %>%
    summarise(prop_in_PA = mean(inPA, na.rm=TRUE)) %>% 
    mutate(year = yr)
  
  results_list[[i]] <- summary_df
}

results_df <- dplyr::bind_rows(results_list)
head(results_df); unique(results_df$year)

write.csv(results_df, "/gpfs/gibbs/pi/jetz/projects/WildlifeInsights/10x10 km spatial layers/prop_wdpa_full_new.csv", row.names=F)
